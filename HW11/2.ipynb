{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","metadata":{"execution":{"iopub.status.busy":"2021-06-14T03:12:22.663050Z","iopub.execute_input":"2021-06-14T03:12:22.663407Z","iopub.status.idle":"2021-06-14T03:12:22.667986Z","shell.execute_reply.started":"2021-06-14T03:12:22.663376Z","shell.execute_reply":"2021-06-14T03:12:22.667181Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Rescales all images by 1/255\ntrain_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntrain_dir = '../input/aid-mini/train'\ntest_dir = '../input/aid-mini/test'\n# train generator\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,              # Target directory\n    target_size=(150, 150), # Resizes all images to 150 × 150\n    batch_size=20,\n    class_mode='categorical')\n\n# validation generator\nvalidation_generator = test_datagen.flow_from_directory(\n    test_dir,         # Target directory\n    target_size=(150, 150), # Resizes all images to 150 × 150\n    batch_size=20,\n    class_mode='categorical')","metadata":{"id":"VHSXeI0Q59kR","outputId":"e87e2f34-c73d-4884-ec32-2ad7cd41fb44","execution":{"iopub.status.busy":"2021-06-14T03:12:22.669536Z","iopub.execute_input":"2021-06-14T03:12:22.670079Z","iopub.status.idle":"2021-06-14T03:12:22.971673Z","shell.execute_reply.started":"2021-06-14T03:12:22.670043Z","shell.execute_reply":"2021-06-14T03:12:22.970700Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Found 1200 images belonging to 30 classes.\nFound 600 images belonging to 30 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.applications.xception import Xception\nconv_base = Xception(include_top=False,\n                  input_shape=(150, 150, 3),\n                  weights=None)\n\nconv_base.summary()","metadata":{"id":"jjM7NAVd72Zq","outputId":"90627572-e083-48aa-c2c1-e02c8fbee0ec","execution":{"iopub.status.busy":"2021-06-14T03:12:22.976127Z","iopub.execute_input":"2021-06-14T03:12:22.976486Z","iopub.status.idle":"2021-06-14T03:12:26.266836Z","shell.execute_reply.started":"2021-06-14T03:12:22.976450Z","shell.execute_reply":"2021-06-14T03:12:26.266069Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Model: \"xception\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n__________________________________________________________________________________________________\nblock1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_1[0][0]                    \n__________________________________________________________________________________________________\nblock1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n__________________________________________________________________________________________________\nblock1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n__________________________________________________________________________________________________\nblock1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n__________________________________________________________________________________________________\nblock1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n__________________________________________________________________________________________________\nblock1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 36, 36, 128)  512         conv2d[0][0]                     \n__________________________________________________________________________________________________\nadd (Add)                       (None, 36, 36, 128)  0           block2_pool[0][0]                \n                                                                 batch_normalization[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv1_act (Activation (None, 36, 36, 128)  0           add[0][0]                        \n__________________________________________________________________________________________________\nblock3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 18, 18, 256)  32768       add[0][0]                        \n__________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 18, 18, 256)  1024        conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 18, 18, 256)  0           block3_pool[0][0]                \n                                                                 batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nblock4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_1[0][0]                      \n__________________________________________________________________________________________________\nblock4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 9, 9, 728)    186368      add_1[0][0]                      \n__________________________________________________________________________________________________\nblock4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 9, 9, 728)    2912        conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 9, 9, 728)    0           block4_pool[0][0]                \n                                                                 batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nblock5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_2[0][0]                      \n__________________________________________________________________________________________________\nblock5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n                                                                 add_2[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_3[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n                                                                 add_3[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_4[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n                                                                 add_4[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_5[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n                                                                 add_5[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_6[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n                                                                 add_6[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_7[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n                                                                 add_7[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_8[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n                                                                 add_8[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_9[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n                                                                 add_9[0][0]                      \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 5, 5, 1024)   745472      add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 5, 5, 1024)   4096        conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n                                                                 batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_11[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n==================================================================================================\nTotal params: 20,861,480\nTrainable params: 20,806,952\nNon-trainable params: 54,528\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(keras.layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(keras.layers.Dense(30, activation='softmax'))\n\n# model.summary()","metadata":{"id":"yIlB5TJQC3CS","execution":{"iopub.status.busy":"2021-06-14T03:12:26.269665Z","iopub.execute_input":"2021-06-14T03:12:26.269928Z","iopub.status.idle":"2021-06-14T03:12:26.757989Z","shell.execute_reply.started":"2021-06-14T03:12:26.269902Z","shell.execute_reply":"2021-06-14T03:12:26.757178Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.build(input_shape=(None,150, 150, 3))\nmodel.summary()","metadata":{"id":"UInSrBlzKjPz","outputId":"7fc1561d-5351-4927-aaf0-3fad7505102b","execution":{"iopub.status.busy":"2021-06-14T03:12:26.759228Z","iopub.execute_input":"2021-06-14T03:12:26.759537Z","iopub.status.idle":"2021-06-14T03:12:26.776382Z","shell.execute_reply.started":"2021-06-14T03:12:26.759505Z","shell.execute_reply":"2021-06-14T03:12:26.775357Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nxception (Functional)        (None, 5, 5, 2048)        20861480  \n_________________________________________________________________\nflatten (Flatten)            (None, 51200)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               6553728   \n_________________________________________________________________\ndense_1 (Dense)              (None, 30)                3870      \n=================================================================\nTotal params: 27,419,078\nTrainable params: 27,364,550\nNon-trainable params: 54,528\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n              loss='categorical_crossentropy',\n              metrics=['acc'])\n\nhistory = model.fit(train_generator,\n                    epochs=100,\n                    validation_data=validation_generator\n                    )","metadata":{"id":"yShHSOSSCd3c","outputId":"c248d154-fea4-40bd-c8ea-ddd4d152e0bb","execution":{"iopub.status.busy":"2021-06-14T03:12:26.777895Z","iopub.execute_input":"2021-06-14T03:12:26.778444Z","iopub.status.idle":"2021-06-14T03:28:01.516235Z","shell.execute_reply.started":"2021-06-14T03:12:26.778342Z","shell.execute_reply":"2021-06-14T03:28:01.515373Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/100\n60/60 [==============================] - 20s 191ms/step - loss: 3.2961 - acc: 0.0998 - val_loss: 3.4012 - val_acc: 0.0333\nEpoch 2/100\n60/60 [==============================] - 9s 155ms/step - loss: 2.3097 - acc: 0.4376 - val_loss: 3.4014 - val_acc: 0.0333\nEpoch 3/100\n60/60 [==============================] - 9s 153ms/step - loss: 1.4918 - acc: 0.7497 - val_loss: 3.4018 - val_acc: 0.0333\nEpoch 4/100\n60/60 [==============================] - 9s 153ms/step - loss: 1.0364 - acc: 0.8482 - val_loss: 3.4027 - val_acc: 0.0333\nEpoch 5/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.6547 - acc: 0.9449 - val_loss: 3.4033 - val_acc: 0.0333\nEpoch 6/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.4345 - acc: 0.9629 - val_loss: 3.4030 - val_acc: 0.0333\nEpoch 7/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.3278 - acc: 0.9783 - val_loss: 3.4054 - val_acc: 0.0333\nEpoch 8/100\n60/60 [==============================] - 9s 156ms/step - loss: 0.2304 - acc: 0.9866 - val_loss: 3.4043 - val_acc: 0.0383\nEpoch 9/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.1560 - acc: 0.9890 - val_loss: 3.3755 - val_acc: 0.0583\nEpoch 10/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0984 - acc: 0.9986 - val_loss: 3.2875 - val_acc: 0.0900\nEpoch 11/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0808 - acc: 0.9978 - val_loss: 3.1073 - val_acc: 0.1250\nEpoch 12/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0845 - acc: 0.9983 - val_loss: 2.7531 - val_acc: 0.2183\nEpoch 13/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0623 - acc: 0.9977 - val_loss: 2.3736 - val_acc: 0.3017\nEpoch 14/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0505 - acc: 0.9953 - val_loss: 2.0455 - val_acc: 0.3900\nEpoch 15/100\n60/60 [==============================] - 9s 151ms/step - loss: 0.0366 - acc: 0.9989 - val_loss: 1.9116 - val_acc: 0.4333\nEpoch 16/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0444 - acc: 0.9984 - val_loss: 1.8280 - val_acc: 0.4467\nEpoch 17/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0312 - acc: 0.9999 - val_loss: 1.7907 - val_acc: 0.4600\nEpoch 18/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0227 - acc: 0.9988 - val_loss: 1.7743 - val_acc: 0.4567\nEpoch 19/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.7744 - val_acc: 0.4667\nEpoch 20/100\n60/60 [==============================] - 9s 155ms/step - loss: 0.0209 - acc: 0.9985 - val_loss: 1.7925 - val_acc: 0.4467\nEpoch 21/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 1.8027 - val_acc: 0.4483\nEpoch 22/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0135 - acc: 0.9999 - val_loss: 1.7776 - val_acc: 0.4600\nEpoch 23/100\n60/60 [==============================] - 9s 151ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 1.7732 - val_acc: 0.4600\nEpoch 24/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 1.7814 - val_acc: 0.4583\nEpoch 25/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0105 - acc: 0.9995 - val_loss: 1.8235 - val_acc: 0.4617\nEpoch 26/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0142 - acc: 0.9998 - val_loss: 1.8042 - val_acc: 0.4467\nEpoch 27/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0231 - acc: 0.9964 - val_loss: 1.7782 - val_acc: 0.4600\nEpoch 28/100\n60/60 [==============================] - 9s 151ms/step - loss: 0.0096 - acc: 0.9989 - val_loss: 1.7489 - val_acc: 0.4500\nEpoch 29/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0106 - acc: 0.9999 - val_loss: 1.7489 - val_acc: 0.4650\nEpoch 30/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 1.7449 - val_acc: 0.4733\nEpoch 31/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.7541 - val_acc: 0.4667\nEpoch 32/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 1.7591 - val_acc: 0.4617\nEpoch 33/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0080 - acc: 0.9991 - val_loss: 1.7997 - val_acc: 0.4683\nEpoch 34/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.8111 - val_acc: 0.4617\nEpoch 35/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0129 - acc: 0.9962 - val_loss: 1.7469 - val_acc: 0.4750\nEpoch 36/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.7335 - val_acc: 0.4783\nEpoch 37/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 1.7487 - val_acc: 0.4683\nEpoch 38/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.7485 - val_acc: 0.4733\nEpoch 39/100\n60/60 [==============================] - 9s 155ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.7397 - val_acc: 0.4683\nEpoch 40/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.7694 - val_acc: 0.4750\nEpoch 41/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.7549 - val_acc: 0.4733\nEpoch 42/100\n60/60 [==============================] - 9s 151ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.7467 - val_acc: 0.4767\nEpoch 43/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 1.7681 - val_acc: 0.4783\nEpoch 44/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.8216 - val_acc: 0.4583\nEpoch 45/100\n60/60 [==============================] - 9s 156ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.7609 - val_acc: 0.4700\nEpoch 46/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.7493 - val_acc: 0.4750\nEpoch 47/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.7496 - val_acc: 0.4750\nEpoch 48/100\n60/60 [==============================] - 10s 158ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 1.9383 - val_acc: 0.4250\nEpoch 49/100\n60/60 [==============================] - 9s 151ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.8283 - val_acc: 0.4567\nEpoch 50/100\n60/60 [==============================] - 9s 151ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.7586 - val_acc: 0.4667\nEpoch 51/100\n60/60 [==============================] - 9s 155ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.7577 - val_acc: 0.4700\nEpoch 52/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.7484 - val_acc: 0.4717\nEpoch 53/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.7628 - val_acc: 0.4667\nEpoch 54/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.7488 - val_acc: 0.4750\nEpoch 55/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.7683 - val_acc: 0.4650\nEpoch 56/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0039 - acc: 0.9983 - val_loss: 1.8540 - val_acc: 0.4400\nEpoch 57/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0295 - acc: 0.9920 - val_loss: 1.9903 - val_acc: 0.4367\nEpoch 58/100\n60/60 [==============================] - 9s 151ms/step - loss: 0.0253 - acc: 0.9952 - val_loss: 1.8378 - val_acc: 0.4617\nEpoch 59/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.8388 - val_acc: 0.4433\nEpoch 60/100\n60/60 [==============================] - 9s 151ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.8138 - val_acc: 0.4450\nEpoch 61/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0019 - acc: 0.9999 - val_loss: 1.8602 - val_acc: 0.4533\nEpoch 62/100\n60/60 [==============================] - 9s 151ms/step - loss: 0.0060 - acc: 0.9991 - val_loss: 1.8502 - val_acc: 0.4467\nEpoch 63/100\n60/60 [==============================] - 9s 156ms/step - loss: 0.0051 - acc: 0.9989 - val_loss: 1.9443 - val_acc: 0.4450\nEpoch 64/100\n60/60 [==============================] - 9s 151ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.8235 - val_acc: 0.4483\nEpoch 65/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.7957 - val_acc: 0.4467\nEpoch 66/100\n60/60 [==============================] - 10s 160ms/step - loss: 0.0015 - acc: 0.9998 - val_loss: 2.1951 - val_acc: 0.3983\nEpoch 67/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0082 - acc: 0.9962 - val_loss: 1.8461 - val_acc: 0.4417\nEpoch 68/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.8253 - val_acc: 0.4583\nEpoch 69/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.8575 - val_acc: 0.4533\nEpoch 70/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.8243 - val_acc: 0.4600\nEpoch 71/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0049 - acc: 0.9989 - val_loss: 1.8257 - val_acc: 0.4517\nEpoch 72/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.7900 - val_acc: 0.4683\nEpoch 73/100\n60/60 [==============================] - 9s 158ms/step - loss: 7.0935e-04 - acc: 1.0000 - val_loss: 1.8109 - val_acc: 0.4700\nEpoch 74/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0055 - acc: 0.9988 - val_loss: 2.1043 - val_acc: 0.4250\nEpoch 75/100\n60/60 [==============================] - 9s 152ms/step - loss: 0.0134 - acc: 0.9967 - val_loss: 2.0855 - val_acc: 0.4333\nEpoch 76/100\n60/60 [==============================] - 10s 163ms/step - loss: 0.0555 - acc: 0.9870 - val_loss: 2.1275 - val_acc: 0.4383\nEpoch 77/100\n60/60 [==============================] - 10s 159ms/step - loss: 0.0135 - acc: 0.9959 - val_loss: 2.0662 - val_acc: 0.4283\nEpoch 78/100\n60/60 [==============================] - 10s 160ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 1.9010 - val_acc: 0.4483\nEpoch 79/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0020 - acc: 0.9998 - val_loss: 1.8979 - val_acc: 0.4533\nEpoch 80/100\n60/60 [==============================] - 9s 155ms/step - loss: 0.0044 - acc: 0.9989 - val_loss: 1.8736 - val_acc: 0.4383\nEpoch 81/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.8829 - val_acc: 0.4383\nEpoch 82/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0053 - acc: 0.9992 - val_loss: 2.3018 - val_acc: 0.3717\nEpoch 83/100\n60/60 [==============================] - 9s 157ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.9030 - val_acc: 0.4367\nEpoch 84/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.9502 - val_acc: 0.4283\nEpoch 85/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.9371 - val_acc: 0.4300\nEpoch 86/100\n60/60 [==============================] - 9s 154ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.9247 - val_acc: 0.4483\nEpoch 87/100\n60/60 [==============================] - 9s 156ms/step - loss: 5.3580e-04 - acc: 1.0000 - val_loss: 1.8988 - val_acc: 0.4483\nEpoch 88/100\n60/60 [==============================] - 9s 153ms/step - loss: 5.8386e-04 - acc: 1.0000 - val_loss: 1.8825 - val_acc: 0.4483\nEpoch 89/100\n60/60 [==============================] - 9s 156ms/step - loss: 6.4946e-04 - acc: 1.0000 - val_loss: 1.8798 - val_acc: 0.4517\nEpoch 90/100\n60/60 [==============================] - 9s 155ms/step - loss: 7.3480e-04 - acc: 1.0000 - val_loss: 1.9065 - val_acc: 0.4317\nEpoch 91/100\n60/60 [==============================] - 9s 153ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.8742 - val_acc: 0.4667\nEpoch 92/100\n60/60 [==============================] - 9s 153ms/step - loss: 3.7607e-04 - acc: 1.0000 - val_loss: 1.8734 - val_acc: 0.4617\nEpoch 93/100\n60/60 [==============================] - 9s 152ms/step - loss: 2.4260e-04 - acc: 1.0000 - val_loss: 1.8711 - val_acc: 0.4617\nEpoch 94/100\n60/60 [==============================] - 9s 153ms/step - loss: 3.1601e-04 - acc: 1.0000 - val_loss: 1.8768 - val_acc: 0.4617\nEpoch 95/100\n60/60 [==============================] - 9s 154ms/step - loss: 3.9637e-04 - acc: 1.0000 - val_loss: 1.8740 - val_acc: 0.4533\nEpoch 96/100\n60/60 [==============================] - 9s 153ms/step - loss: 4.2526e-04 - acc: 1.0000 - val_loss: 1.8663 - val_acc: 0.4600\nEpoch 97/100\n60/60 [==============================] - 9s 155ms/step - loss: 3.6326e-04 - acc: 1.0000 - val_loss: 1.8448 - val_acc: 0.4617\nEpoch 98/100\n60/60 [==============================] - 9s 153ms/step - loss: 2.9598e-04 - acc: 1.0000 - val_loss: 1.8418 - val_acc: 0.4600\nEpoch 99/100\n60/60 [==============================] - 9s 152ms/step - loss: 2.1219e-04 - acc: 1.0000 - val_loss: 1.8466 - val_acc: 0.4600\nEpoch 100/100\n60/60 [==============================] - 9s 152ms/step - loss: 6.8607e-04 - acc: 1.0000 - val_loss: 1.9507 - val_acc: 0.4400\n","output_type":"stream"}]},{"cell_type":"code","source":"\nconv_base = Xception(include_top=False,\n                  input_shape=(150, 150, 3),\n                  weights='imagenet')\n\nconv_base.summary()","metadata":{"id":"xVLMbWsbMDA_","execution":{"iopub.status.busy":"2021-06-14T03:28:01.517791Z","iopub.execute_input":"2021-06-14T03:28:01.518170Z","iopub.status.idle":"2021-06-14T03:28:05.039499Z","shell.execute_reply.started":"2021-06-14T03:28:01.518130Z","shell.execute_reply":"2021-06-14T03:28:05.034545Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83689472/83683744 [==============================] - 2s 0us/step\nModel: \"xception\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n__________________________________________________________________________________________________\nblock1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_2[0][0]                    \n__________________________________________________________________________________________________\nblock1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n__________________________________________________________________________________________________\nblock1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n__________________________________________________________________________________________________\nblock1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n__________________________________________________________________________________________________\nblock1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n__________________________________________________________________________________________________\nblock1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 36, 36, 128)  512         conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 36, 36, 128)  0           block2_pool[0][0]                \n                                                                 batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nblock3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_12[0][0]                     \n__________________________________________________________________________________________________\nblock3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 18, 18, 256)  32768       add_12[0][0]                     \n__________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 18, 18, 256)  1024        conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nadd_13 (Add)                    (None, 18, 18, 256)  0           block3_pool[0][0]                \n                                                                 batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nblock4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_13[0][0]                     \n__________________________________________________________________________________________________\nblock4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 9, 9, 728)    186368      add_13[0][0]                     \n__________________________________________________________________________________________________\nblock4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 9, 9, 728)    2912        conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nadd_14 (Add)                    (None, 9, 9, 728)    0           block4_pool[0][0]                \n                                                                 batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nblock5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_14[0][0]                     \n__________________________________________________________________________________________________\nblock5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_15 (Add)                    (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n                                                                 add_14[0][0]                     \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_15[0][0]                     \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_16 (Add)                    (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n                                                                 add_15[0][0]                     \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_16[0][0]                     \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_17 (Add)                    (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n                                                                 add_16[0][0]                     \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_17[0][0]                     \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_18 (Add)                    (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n                                                                 add_17[0][0]                     \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_18[0][0]                     \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_19 (Add)                    (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n                                                                 add_18[0][0]                     \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_19[0][0]                     \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_20 (Add)                    (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n                                                                 add_19[0][0]                     \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_20[0][0]                     \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_21 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n                                                                 add_20[0][0]                     \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_21[0][0]                     \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_22 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n                                                                 add_21[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_22[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 5, 5, 1024)   745472      add_22[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 5, 5, 1024)   4096        conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nadd_23 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n                                                                 batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_23[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n==================================================================================================\nTotal params: 20,861,480\nTrainable params: 20,806,952\nNon-trainable params: 54,528\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(keras.layers.Flatten())\n# model.add(layers.Dense(128, activation='relu'))\nmodel.add(keras.layers.Dense(30, activation='softmax'))\n\n# model.summary()","metadata":{"id":"foVQQgh2MDBV","execution":{"iopub.status.busy":"2021-06-14T03:28:05.040996Z","iopub.execute_input":"2021-06-14T03:28:05.041485Z","iopub.status.idle":"2021-06-14T03:28:05.495258Z","shell.execute_reply.started":"2021-06-14T03:28:05.041449Z","shell.execute_reply":"2021-06-14T03:28:05.494323Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"conv_base.trainable = False\n\n","metadata":{"id":"1z53cwb4Mqcq","execution":{"iopub.status.busy":"2021-06-14T03:28:05.501745Z","iopub.execute_input":"2021-06-14T03:28:05.503965Z","iopub.status.idle":"2021-06-14T03:28:05.518364Z","shell.execute_reply.started":"2021-06-14T03:28:05.503922Z","shell.execute_reply":"2021-06-14T03:28:05.514436Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.build(input_shape=(None,150, 150, 3))\nmodel.summary()","metadata":{"id":"awf2o4yOMDBX","execution":{"iopub.status.busy":"2021-06-14T03:28:05.521412Z","iopub.execute_input":"2021-06-14T03:28:05.521712Z","iopub.status.idle":"2021-06-14T03:28:05.549495Z","shell.execute_reply.started":"2021-06-14T03:28:05.521683Z","shell.execute_reply":"2021-06-14T03:28:05.548757Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nxception (Functional)        (None, 5, 5, 2048)        20861480  \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 51200)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 30)                1536030   \n=================================================================\nTotal params: 22,397,510\nTrainable params: 1,536,030\nNon-trainable params: 20,861,480\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n              loss='categorical_crossentropy',\n              metrics=['acc'])\n\nhistory = model.fit(train_generator,\n                    epochs=100,\n                    validation_data=validation_generator\n                    )","metadata":{"id":"5xUIc_xEMDBZ","execution":{"iopub.status.busy":"2021-06-14T03:28:05.552974Z","iopub.execute_input":"2021-06-14T03:28:05.554957Z","iopub.status.idle":"2021-06-14T03:35:45.473607Z","shell.execute_reply.started":"2021-06-14T03:28:05.554921Z","shell.execute_reply":"2021-06-14T03:35:45.472772Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/100\n60/60 [==============================] - 8s 92ms/step - loss: 3.2549 - acc: 0.1058 - val_loss: 2.3336 - val_acc: 0.4267\nEpoch 2/100\n60/60 [==============================] - 4s 75ms/step - loss: 1.8317 - acc: 0.6164 - val_loss: 1.8458 - val_acc: 0.5833\nEpoch 3/100\n60/60 [==============================] - 5s 77ms/step - loss: 1.2235 - acc: 0.8075 - val_loss: 1.6110 - val_acc: 0.6283\nEpoch 4/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.9698 - acc: 0.8624 - val_loss: 1.4778 - val_acc: 0.6383\nEpoch 5/100\n60/60 [==============================] - 5s 78ms/step - loss: 0.7004 - acc: 0.9314 - val_loss: 1.3964 - val_acc: 0.6700\nEpoch 6/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.6122 - acc: 0.9443 - val_loss: 1.3402 - val_acc: 0.6617\nEpoch 7/100\n60/60 [==============================] - 5s 80ms/step - loss: 0.5084 - acc: 0.9563 - val_loss: 1.2952 - val_acc: 0.6767\nEpoch 8/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.4566 - acc: 0.9689 - val_loss: 1.2647 - val_acc: 0.6767\nEpoch 9/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.3913 - acc: 0.9767 - val_loss: 1.2443 - val_acc: 0.6783\nEpoch 10/100\n60/60 [==============================] - 5s 78ms/step - loss: 0.3739 - acc: 0.9805 - val_loss: 1.2179 - val_acc: 0.6867\nEpoch 11/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.2918 - acc: 0.9799 - val_loss: 1.2042 - val_acc: 0.6900\nEpoch 12/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.2850 - acc: 0.9909 - val_loss: 1.1871 - val_acc: 0.6950\nEpoch 13/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.2598 - acc: 0.9917 - val_loss: 1.1790 - val_acc: 0.6917\nEpoch 14/100\n60/60 [==============================] - 5s 82ms/step - loss: 0.2558 - acc: 0.9902 - val_loss: 1.1694 - val_acc: 0.6867\nEpoch 15/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.2639 - acc: 0.9907 - val_loss: 1.1607 - val_acc: 0.6900\nEpoch 16/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.2526 - acc: 0.9924 - val_loss: 1.1532 - val_acc: 0.6967\nEpoch 17/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.2333 - acc: 0.9886 - val_loss: 1.1511 - val_acc: 0.6967\nEpoch 18/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.1848 - acc: 0.9941 - val_loss: 1.1469 - val_acc: 0.6933\nEpoch 19/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.1817 - acc: 0.9937 - val_loss: 1.1410 - val_acc: 0.6967\nEpoch 20/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.1856 - acc: 0.9937 - val_loss: 1.1351 - val_acc: 0.6983\nEpoch 21/100\n60/60 [==============================] - 5s 81ms/step - loss: 0.1699 - acc: 0.9951 - val_loss: 1.1344 - val_acc: 0.6983\nEpoch 22/100\n60/60 [==============================] - 5s 79ms/step - loss: 0.1728 - acc: 0.9943 - val_loss: 1.1332 - val_acc: 0.6917\nEpoch 23/100\n60/60 [==============================] - 5s 75ms/step - loss: 0.1477 - acc: 0.9945 - val_loss: 1.1277 - val_acc: 0.6967\nEpoch 24/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.1524 - acc: 0.9952 - val_loss: 1.1278 - val_acc: 0.6933\nEpoch 25/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.1379 - acc: 0.9966 - val_loss: 1.1257 - val_acc: 0.6933\nEpoch 26/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.1343 - acc: 0.9969 - val_loss: 1.1234 - val_acc: 0.6933\nEpoch 27/100\n60/60 [==============================] - 5s 83ms/step - loss: 0.1287 - acc: 0.9958 - val_loss: 1.1240 - val_acc: 0.6933\nEpoch 28/100\n60/60 [==============================] - 5s 75ms/step - loss: 0.1413 - acc: 0.9924 - val_loss: 1.1221 - val_acc: 0.6950\nEpoch 29/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.1385 - acc: 0.9969 - val_loss: 1.1216 - val_acc: 0.6983\nEpoch 30/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.1146 - acc: 0.9972 - val_loss: 1.1207 - val_acc: 0.6950\nEpoch 31/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.1383 - acc: 0.9929 - val_loss: 1.1200 - val_acc: 0.6967\nEpoch 32/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.1232 - acc: 0.9951 - val_loss: 1.1194 - val_acc: 0.6967\nEpoch 33/100\n60/60 [==============================] - 4s 75ms/step - loss: 0.1542 - acc: 0.9957 - val_loss: 1.1219 - val_acc: 0.6967\nEpoch 34/100\n60/60 [==============================] - 5s 85ms/step - loss: 0.1019 - acc: 0.9979 - val_loss: 1.1192 - val_acc: 0.6967\nEpoch 35/100\n60/60 [==============================] - 4s 75ms/step - loss: 0.1160 - acc: 0.9963 - val_loss: 1.1198 - val_acc: 0.6983\nEpoch 36/100\n60/60 [==============================] - 5s 78ms/step - loss: 0.1265 - acc: 0.9969 - val_loss: 1.1198 - val_acc: 0.6983\nEpoch 37/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.0969 - acc: 0.9991 - val_loss: 1.1210 - val_acc: 0.6983\nEpoch 38/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.0985 - acc: 0.9974 - val_loss: 1.1206 - val_acc: 0.7000\nEpoch 39/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.1106 - acc: 0.9956 - val_loss: 1.1226 - val_acc: 0.7000\nEpoch 40/100\n60/60 [==============================] - 4s 75ms/step - loss: 0.1064 - acc: 0.9973 - val_loss: 1.1215 - val_acc: 0.7000\nEpoch 41/100\n60/60 [==============================] - 5s 84ms/step - loss: 0.1138 - acc: 0.9963 - val_loss: 1.1222 - val_acc: 0.7000\nEpoch 42/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.1136 - acc: 0.9978 - val_loss: 1.1232 - val_acc: 0.6983\nEpoch 43/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.0830 - acc: 0.9983 - val_loss: 1.1235 - val_acc: 0.6983\nEpoch 44/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0961 - acc: 0.9981 - val_loss: 1.1248 - val_acc: 0.7000\nEpoch 45/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.0886 - acc: 0.9989 - val_loss: 1.1246 - val_acc: 0.6983\nEpoch 46/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0801 - acc: 0.9981 - val_loss: 1.1246 - val_acc: 0.6983\nEpoch 47/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.1054 - acc: 0.9983 - val_loss: 1.1279 - val_acc: 0.7017\nEpoch 48/100\n60/60 [==============================] - 5s 83ms/step - loss: 0.0899 - acc: 0.9983 - val_loss: 1.1273 - val_acc: 0.7000\nEpoch 49/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.0739 - acc: 0.9993 - val_loss: 1.1283 - val_acc: 0.7017\nEpoch 50/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.0785 - acc: 0.9996 - val_loss: 1.1288 - val_acc: 0.7017\nEpoch 51/100\n60/60 [==============================] - 5s 78ms/step - loss: 0.0772 - acc: 0.9992 - val_loss: 1.1301 - val_acc: 0.7017\nEpoch 52/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.0930 - acc: 0.9972 - val_loss: 1.1328 - val_acc: 0.7000\nEpoch 53/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0773 - acc: 0.9994 - val_loss: 1.1337 - val_acc: 0.6983\nEpoch 54/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.0619 - acc: 0.9985 - val_loss: 1.1351 - val_acc: 0.6950\nEpoch 55/100\n60/60 [==============================] - 5s 80ms/step - loss: 0.0795 - acc: 0.9991 - val_loss: 1.1347 - val_acc: 0.7000\nEpoch 56/100\n60/60 [==============================] - 5s 78ms/step - loss: 0.0861 - acc: 0.9953 - val_loss: 1.1375 - val_acc: 0.6983\nEpoch 57/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.0902 - acc: 0.9971 - val_loss: 1.1379 - val_acc: 0.7017\nEpoch 58/100\n60/60 [==============================] - 5s 78ms/step - loss: 0.0647 - acc: 0.9995 - val_loss: 1.1404 - val_acc: 0.6983\nEpoch 59/100\n60/60 [==============================] - 4s 75ms/step - loss: 0.0665 - acc: 0.9997 - val_loss: 1.1407 - val_acc: 0.7033\nEpoch 60/100\n60/60 [==============================] - 5s 78ms/step - loss: 0.0819 - acc: 0.9981 - val_loss: 1.1421 - val_acc: 0.6983\nEpoch 61/100\n60/60 [==============================] - 4s 75ms/step - loss: 0.0687 - acc: 0.9993 - val_loss: 1.1430 - val_acc: 0.7017\nEpoch 62/100\n60/60 [==============================] - 5s 82ms/step - loss: 0.0686 - acc: 0.9985 - val_loss: 1.1450 - val_acc: 0.6983\nEpoch 63/100\n60/60 [==============================] - 5s 80ms/step - loss: 0.0796 - acc: 0.9973 - val_loss: 1.1461 - val_acc: 0.7000\nEpoch 64/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.0676 - acc: 0.9966 - val_loss: 1.1475 - val_acc: 0.7000\nEpoch 65/100\n60/60 [==============================] - 5s 79ms/step - loss: 0.0612 - acc: 0.9994 - val_loss: 1.1485 - val_acc: 0.6983\nEpoch 66/100\n60/60 [==============================] - 4s 75ms/step - loss: 0.0609 - acc: 0.9992 - val_loss: 1.1508 - val_acc: 0.7017\nEpoch 67/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0732 - acc: 0.9959 - val_loss: 1.1518 - val_acc: 0.7017\nEpoch 68/100\n60/60 [==============================] - 5s 75ms/step - loss: 0.0760 - acc: 0.9979 - val_loss: 1.1531 - val_acc: 0.7017\nEpoch 69/100\n60/60 [==============================] - 5s 81ms/step - loss: 0.0505 - acc: 0.9992 - val_loss: 1.1564 - val_acc: 0.7033\nEpoch 70/100\n60/60 [==============================] - 5s 78ms/step - loss: 0.0513 - acc: 0.9993 - val_loss: 1.1559 - val_acc: 0.7017\nEpoch 71/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.0737 - acc: 0.9999 - val_loss: 1.1578 - val_acc: 0.7033\nEpoch 72/100\n60/60 [==============================] - 5s 75ms/step - loss: 0.0537 - acc: 0.9999 - val_loss: 1.1591 - val_acc: 0.7033\nEpoch 73/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.0659 - acc: 0.9974 - val_loss: 1.1615 - val_acc: 0.7050\nEpoch 74/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.0635 - acc: 0.9998 - val_loss: 1.1632 - val_acc: 0.7050\nEpoch 75/100\n60/60 [==============================] - 5s 75ms/step - loss: 0.0503 - acc: 0.9998 - val_loss: 1.1637 - val_acc: 0.7050\nEpoch 76/100\n60/60 [==============================] - 5s 80ms/step - loss: 0.0640 - acc: 0.9997 - val_loss: 1.1661 - val_acc: 0.7050\nEpoch 77/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0533 - acc: 0.9995 - val_loss: 1.1682 - val_acc: 0.7050\nEpoch 78/100\n60/60 [==============================] - 4s 71ms/step - loss: 0.0567 - acc: 1.0000 - val_loss: 1.1694 - val_acc: 0.7050\nEpoch 79/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.0498 - acc: 0.9994 - val_loss: 1.1705 - val_acc: 0.7050\nEpoch 80/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0413 - acc: 0.9999 - val_loss: 1.1725 - val_acc: 0.7050\nEpoch 81/100\n60/60 [==============================] - 4s 72ms/step - loss: 0.0489 - acc: 0.9999 - val_loss: 1.1738 - val_acc: 0.7050\nEpoch 82/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0619 - acc: 0.9994 - val_loss: 1.1759 - val_acc: 0.7067\nEpoch 83/100\n60/60 [==============================] - 5s 80ms/step - loss: 0.0414 - acc: 0.9991 - val_loss: 1.1779 - val_acc: 0.7067\nEpoch 84/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0592 - acc: 0.9991 - val_loss: 1.1792 - val_acc: 0.7083\nEpoch 85/100\n60/60 [==============================] - 4s 73ms/step - loss: 0.0484 - acc: 0.9995 - val_loss: 1.1825 - val_acc: 0.7067\nEpoch 86/100\n60/60 [==============================] - 4s 72ms/step - loss: 0.0406 - acc: 0.9990 - val_loss: 1.1828 - val_acc: 0.7067\nEpoch 87/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0689 - acc: 0.9983 - val_loss: 1.1847 - val_acc: 0.7067\nEpoch 88/100\n60/60 [==============================] - 4s 71ms/step - loss: 0.0500 - acc: 0.9990 - val_loss: 1.1859 - val_acc: 0.7050\nEpoch 89/100\n60/60 [==============================] - 5s 75ms/step - loss: 0.0526 - acc: 1.0000 - val_loss: 1.1882 - val_acc: 0.7050\nEpoch 90/100\n60/60 [==============================] - 5s 78ms/step - loss: 0.0461 - acc: 1.0000 - val_loss: 1.1894 - val_acc: 0.7050\nEpoch 91/100\n60/60 [==============================] - 4s 72ms/step - loss: 0.0400 - acc: 1.0000 - val_loss: 1.1923 - val_acc: 0.7050\nEpoch 92/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0512 - acc: 1.0000 - val_loss: 1.1943 - val_acc: 0.7050\nEpoch 93/100\n60/60 [==============================] - 4s 72ms/step - loss: 0.0368 - acc: 1.0000 - val_loss: 1.1959 - val_acc: 0.7050\nEpoch 94/100\n60/60 [==============================] - 4s 74ms/step - loss: 0.0324 - acc: 1.0000 - val_loss: 1.1983 - val_acc: 0.7067\nEpoch 95/100\n60/60 [==============================] - 4s 71ms/step - loss: 0.0354 - acc: 1.0000 - val_loss: 1.1996 - val_acc: 0.7050\nEpoch 96/100\n60/60 [==============================] - 4s 72ms/step - loss: 0.0469 - acc: 1.0000 - val_loss: 1.2018 - val_acc: 0.7067\nEpoch 97/100\n60/60 [==============================] - 5s 81ms/step - loss: 0.0351 - acc: 1.0000 - val_loss: 1.2035 - val_acc: 0.7050\nEpoch 98/100\n60/60 [==============================] - 4s 71ms/step - loss: 0.0347 - acc: 1.0000 - val_loss: 1.2052 - val_acc: 0.7050\nEpoch 99/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0330 - acc: 1.0000 - val_loss: 1.2077 - val_acc: 0.7067\nEpoch 100/100\n60/60 [==============================] - 4s 72ms/step - loss: 0.0440 - acc: 1.0000 - val_loss: 1.2097 - val_acc: 0.7083\n","output_type":"stream"}]},{"cell_type":"code","source":"conv_base.trainable = True\n\nset_trainable = False\nfor layer in conv_base.layers:\n  if layer.name == 'block12_sepconv1':\n    set_trainable = True\n\n  if set_trainable:\n    layer.trainable = True\n  else:\n    layer.trainable = False\n\nmodel.summary()","metadata":{"id":"JLcNrIKfJLhO","execution":{"iopub.status.busy":"2021-06-14T03:35:45.476686Z","iopub.execute_input":"2021-06-14T03:35:45.476958Z","iopub.status.idle":"2021-06-14T03:35:45.500630Z","shell.execute_reply.started":"2021-06-14T03:35:45.476931Z","shell.execute_reply":"2021-06-14T03:35:45.499445Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nxception (Functional)        (None, 5, 5, 2048)        20861480  \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 51200)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 30)                1536030   \n=================================================================\nTotal params: 22,397,510\nTrainable params: 9,938,390\nNon-trainable params: 12,459,120\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n              loss='categorical_crossentropy',\n              metrics=['acc'])\n\nhistory = model.fit(train_generator,\n                    epochs=100,\n                    validation_data=validation_generator\n                    )","metadata":{"id":"x4ZitkSrJLhr","execution":{"iopub.status.busy":"2021-06-14T03:35:45.502040Z","iopub.execute_input":"2021-06-14T03:35:45.502396Z","iopub.status.idle":"2021-06-14T03:43:47.838242Z","shell.execute_reply.started":"2021-06-14T03:35:45.502360Z","shell.execute_reply":"2021-06-14T03:43:47.837372Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/100\n60/60 [==============================] - 8s 94ms/step - loss: 1.0770 - acc: 0.7827 - val_loss: 1.3015 - val_acc: 0.6900\nEpoch 2/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.2992 - acc: 0.9713 - val_loss: 1.2768 - val_acc: 0.7033\nEpoch 3/100\n60/60 [==============================] - 5s 83ms/step - loss: 0.1707 - acc: 0.9849 - val_loss: 1.3021 - val_acc: 0.7050\nEpoch 4/100\n60/60 [==============================] - 5s 81ms/step - loss: 0.0829 - acc: 0.9926 - val_loss: 1.2362 - val_acc: 0.7033\nEpoch 5/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0759 - acc: 0.9892 - val_loss: 1.2015 - val_acc: 0.7000\nEpoch 6/100\n60/60 [==============================] - 5s 80ms/step - loss: 0.0448 - acc: 1.0000 - val_loss: 1.1546 - val_acc: 0.7017\nEpoch 7/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0327 - acc: 0.9996 - val_loss: 1.1098 - val_acc: 0.7117\nEpoch 8/100\n60/60 [==============================] - 5s 81ms/step - loss: 0.0275 - acc: 1.0000 - val_loss: 1.0892 - val_acc: 0.7183\nEpoch 9/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0216 - acc: 0.9998 - val_loss: 1.0784 - val_acc: 0.7283\nEpoch 10/100\n60/60 [==============================] - 5s 85ms/step - loss: 0.0191 - acc: 0.9997 - val_loss: 1.0701 - val_acc: 0.7267\nEpoch 11/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.0725 - val_acc: 0.7267\nEpoch 12/100\n60/60 [==============================] - 5s 82ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 1.0630 - val_acc: 0.7267\nEpoch 13/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.0492 - val_acc: 0.7317\nEpoch 14/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 1.0433 - val_acc: 0.7367\nEpoch 15/100\n60/60 [==============================] - 5s 80ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 1.0395 - val_acc: 0.7333\nEpoch 16/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 1.0426 - val_acc: 0.7367\nEpoch 17/100\n60/60 [==============================] - 5s 87ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0526 - val_acc: 0.7350\nEpoch 18/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0617 - val_acc: 0.7317\nEpoch 19/100\n60/60 [==============================] - 5s 81ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0468 - val_acc: 0.7400\nEpoch 20/100\n60/60 [==============================] - 5s 80ms/step - loss: 0.0063 - acc: 0.9998 - val_loss: 1.0657 - val_acc: 0.7350\nEpoch 21/100\n60/60 [==============================] - 5s 79ms/step - loss: 0.0086 - acc: 0.9986 - val_loss: 1.0482 - val_acc: 0.7433\nEpoch 22/100\n60/60 [==============================] - 5s 81ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 1.0432 - val_acc: 0.7450\nEpoch 23/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.0528 - val_acc: 0.7417\nEpoch 24/100\n60/60 [==============================] - 5s 87ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.0408 - val_acc: 0.7467\nEpoch 25/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 1.0299 - val_acc: 0.7467\nEpoch 26/100\n60/60 [==============================] - 5s 81ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 1.0288 - val_acc: 0.7450\nEpoch 27/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.0282 - val_acc: 0.7483\nEpoch 28/100\n60/60 [==============================] - 5s 82ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.0254 - val_acc: 0.7517\nEpoch 29/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.0267 - val_acc: 0.7533\nEpoch 30/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.0207 - val_acc: 0.7500\nEpoch 31/100\n60/60 [==============================] - 5s 87ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.0206 - val_acc: 0.7483\nEpoch 32/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.0208 - val_acc: 0.7467\nEpoch 33/100\n60/60 [==============================] - 5s 82ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.0221 - val_acc: 0.7450\nEpoch 34/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0225 - val_acc: 0.7500\nEpoch 35/100\n60/60 [==============================] - 5s 80ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 1.0422 - val_acc: 0.7467\nEpoch 36/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.0579 - val_acc: 0.7467\nEpoch 37/100\n60/60 [==============================] - 5s 78ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0443 - val_acc: 0.7467\nEpoch 38/100\n60/60 [==============================] - 5s 88ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0472 - val_acc: 0.7467\nEpoch 39/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0453 - val_acc: 0.7467\nEpoch 40/100\n60/60 [==============================] - 5s 80ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.0444 - val_acc: 0.7483\nEpoch 41/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0443 - val_acc: 0.7450\nEpoch 42/100\n60/60 [==============================] - 5s 80ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0517 - val_acc: 0.7483\nEpoch 43/100\n60/60 [==============================] - 5s 75ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0440 - val_acc: 0.7483\nEpoch 44/100\n60/60 [==============================] - 5s 75ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0429 - val_acc: 0.7483\nEpoch 45/100\n60/60 [==============================] - 5s 88ms/step - loss: 9.2371e-04 - acc: 1.0000 - val_loss: 1.0419 - val_acc: 0.7500\nEpoch 46/100\n60/60 [==============================] - 5s 77ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0441 - val_acc: 0.7533\nEpoch 47/100\n60/60 [==============================] - 5s 81ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.0439 - val_acc: 0.7517\nEpoch 48/100\n60/60 [==============================] - 5s 76ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.7533\nEpoch 49/100\n60/60 [==============================] - 5s 80ms/step - loss: 9.9685e-04 - acc: 1.0000 - val_loss: 1.0405 - val_acc: 0.7500\nEpoch 50/100\n60/60 [==============================] - 5s 76ms/step - loss: 8.2775e-04 - acc: 1.0000 - val_loss: 1.0441 - val_acc: 0.7450\nEpoch 51/100\n60/60 [==============================] - 5s 77ms/step - loss: 8.0178e-04 - acc: 1.0000 - val_loss: 1.0419 - val_acc: 0.7500\nEpoch 52/100\n60/60 [==============================] - 5s 86ms/step - loss: 9.8510e-04 - acc: 1.0000 - val_loss: 1.0418 - val_acc: 0.7517\nEpoch 53/100\n60/60 [==============================] - 5s 77ms/step - loss: 9.4305e-04 - acc: 1.0000 - val_loss: 1.0369 - val_acc: 0.7483\nEpoch 54/100\n60/60 [==============================] - 5s 82ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0467 - val_acc: 0.7517\nEpoch 55/100\n60/60 [==============================] - 5s 76ms/step - loss: 6.4245e-04 - acc: 1.0000 - val_loss: 1.0389 - val_acc: 0.7517\nEpoch 56/100\n60/60 [==============================] - 5s 82ms/step - loss: 5.7097e-04 - acc: 1.0000 - val_loss: 1.0414 - val_acc: 0.7517\nEpoch 57/100\n60/60 [==============================] - 5s 76ms/step - loss: 5.8554e-04 - acc: 1.0000 - val_loss: 1.0368 - val_acc: 0.7533\nEpoch 58/100\n60/60 [==============================] - 5s 83ms/step - loss: 6.2783e-04 - acc: 1.0000 - val_loss: 1.0468 - val_acc: 0.7567\nEpoch 59/100\n60/60 [==============================] - 5s 82ms/step - loss: 7.3032e-04 - acc: 1.0000 - val_loss: 1.0496 - val_acc: 0.7567\nEpoch 60/100\n60/60 [==============================] - 5s 78ms/step - loss: 7.2167e-04 - acc: 1.0000 - val_loss: 1.0479 - val_acc: 0.7567\nEpoch 61/100\n60/60 [==============================] - 5s 82ms/step - loss: 6.3677e-04 - acc: 1.0000 - val_loss: 1.0486 - val_acc: 0.7567\nEpoch 62/100\n60/60 [==============================] - 5s 77ms/step - loss: 5.0077e-04 - acc: 1.0000 - val_loss: 1.0476 - val_acc: 0.7567\nEpoch 63/100\n60/60 [==============================] - 5s 81ms/step - loss: 6.2806e-04 - acc: 1.0000 - val_loss: 1.0523 - val_acc: 0.7567\nEpoch 64/100\n60/60 [==============================] - 5s 78ms/step - loss: 4.1991e-04 - acc: 1.0000 - val_loss: 1.0471 - val_acc: 0.7567\nEpoch 65/100\n60/60 [==============================] - 5s 87ms/step - loss: 5.4358e-04 - acc: 1.0000 - val_loss: 1.0475 - val_acc: 0.7567\nEpoch 66/100\n60/60 [==============================] - 5s 79ms/step - loss: 5.1202e-04 - acc: 1.0000 - val_loss: 1.0462 - val_acc: 0.7567\nEpoch 67/100\n60/60 [==============================] - 5s 81ms/step - loss: 4.9604e-04 - acc: 1.0000 - val_loss: 1.0474 - val_acc: 0.7617\nEpoch 68/100\n60/60 [==============================] - 5s 77ms/step - loss: 5.5706e-04 - acc: 1.0000 - val_loss: 1.0482 - val_acc: 0.7583\nEpoch 69/100\n60/60 [==============================] - 5s 77ms/step - loss: 5.2620e-04 - acc: 1.0000 - val_loss: 1.0445 - val_acc: 0.7567\nEpoch 70/100\n60/60 [==============================] - 5s 82ms/step - loss: 4.4715e-04 - acc: 1.0000 - val_loss: 1.0427 - val_acc: 0.7600\nEpoch 71/100\n60/60 [==============================] - 5s 78ms/step - loss: 4.2319e-04 - acc: 1.0000 - val_loss: 1.0425 - val_acc: 0.7567\nEpoch 72/100\n60/60 [==============================] - 5s 86ms/step - loss: 4.1176e-04 - acc: 1.0000 - val_loss: 1.0430 - val_acc: 0.7617\nEpoch 73/100\n60/60 [==============================] - 5s 76ms/step - loss: 4.7376e-04 - acc: 1.0000 - val_loss: 1.0454 - val_acc: 0.7583\nEpoch 74/100\n60/60 [==============================] - 5s 82ms/step - loss: 4.1872e-04 - acc: 1.0000 - val_loss: 1.0456 - val_acc: 0.7567\nEpoch 75/100\n60/60 [==============================] - 5s 77ms/step - loss: 2.9365e-04 - acc: 1.0000 - val_loss: 1.0481 - val_acc: 0.7567\nEpoch 76/100\n60/60 [==============================] - 5s 77ms/step - loss: 4.2731e-04 - acc: 1.0000 - val_loss: 1.0419 - val_acc: 0.7550\nEpoch 77/100\n60/60 [==============================] - 5s 82ms/step - loss: 2.7129e-04 - acc: 1.0000 - val_loss: 1.0422 - val_acc: 0.7600\nEpoch 78/100\n60/60 [==============================] - 5s 76ms/step - loss: 8.5432e-04 - acc: 1.0000 - val_loss: 1.0579 - val_acc: 0.7617\nEpoch 79/100\n60/60 [==============================] - 5s 85ms/step - loss: 3.4641e-04 - acc: 1.0000 - val_loss: 1.0527 - val_acc: 0.7617\nEpoch 80/100\n60/60 [==============================] - 5s 76ms/step - loss: 3.3054e-04 - acc: 1.0000 - val_loss: 1.0491 - val_acc: 0.7650\nEpoch 81/100\n60/60 [==============================] - 5s 80ms/step - loss: 2.4906e-04 - acc: 1.0000 - val_loss: 1.0484 - val_acc: 0.7633\nEpoch 82/100\n60/60 [==============================] - 5s 76ms/step - loss: 2.1588e-04 - acc: 1.0000 - val_loss: 1.0493 - val_acc: 0.7617\nEpoch 83/100\n60/60 [==============================] - 5s 77ms/step - loss: 3.9854e-04 - acc: 1.0000 - val_loss: 1.0470 - val_acc: 0.7583\nEpoch 84/100\n60/60 [==============================] - 5s 80ms/step - loss: 1.8429e-04 - acc: 1.0000 - val_loss: 1.0464 - val_acc: 0.7600\nEpoch 85/100\n60/60 [==============================] - 5s 75ms/step - loss: 2.1179e-04 - acc: 1.0000 - val_loss: 1.0502 - val_acc: 0.7567\nEpoch 86/100\n60/60 [==============================] - 5s 87ms/step - loss: 3.1641e-04 - acc: 1.0000 - val_loss: 1.0593 - val_acc: 0.7600\nEpoch 87/100\n60/60 [==============================] - 5s 77ms/step - loss: 2.0110e-04 - acc: 1.0000 - val_loss: 1.0639 - val_acc: 0.7617\nEpoch 88/100\n60/60 [==============================] - 5s 80ms/step - loss: 3.0948e-04 - acc: 1.0000 - val_loss: 1.0661 - val_acc: 0.7533\nEpoch 89/100\n60/60 [==============================] - 5s 77ms/step - loss: 1.8093e-04 - acc: 1.0000 - val_loss: 1.0748 - val_acc: 0.7567\nEpoch 90/100\n60/60 [==============================] - 5s 78ms/step - loss: 2.1310e-04 - acc: 1.0000 - val_loss: 1.0638 - val_acc: 0.7583\nEpoch 91/100\n60/60 [==============================] - 5s 78ms/step - loss: 1.8085e-04 - acc: 1.0000 - val_loss: 1.0582 - val_acc: 0.7600\nEpoch 92/100\n60/60 [==============================] - 5s 76ms/step - loss: 2.0376e-04 - acc: 1.0000 - val_loss: 1.0597 - val_acc: 0.7583\nEpoch 93/100\n60/60 [==============================] - 5s 89ms/step - loss: 3.9944e-04 - acc: 1.0000 - val_loss: 1.0533 - val_acc: 0.7583\nEpoch 94/100\n60/60 [==============================] - 5s 76ms/step - loss: 1.6615e-04 - acc: 1.0000 - val_loss: 1.0598 - val_acc: 0.7583\nEpoch 95/100\n60/60 [==============================] - 5s 80ms/step - loss: 1.8005e-04 - acc: 1.0000 - val_loss: 1.0569 - val_acc: 0.7617\nEpoch 96/100\n60/60 [==============================] - 5s 76ms/step - loss: 1.6473e-04 - acc: 1.0000 - val_loss: 1.0555 - val_acc: 0.7600\nEpoch 97/100\n60/60 [==============================] - 5s 80ms/step - loss: 2.5746e-04 - acc: 1.0000 - val_loss: 1.0505 - val_acc: 0.7633\nEpoch 98/100\n60/60 [==============================] - 5s 76ms/step - loss: 1.9786e-04 - acc: 1.0000 - val_loss: 1.0581 - val_acc: 0.7633\nEpoch 99/100\n60/60 [==============================] - 5s 77ms/step - loss: 1.5826e-04 - acc: 1.0000 - val_loss: 1.0602 - val_acc: 0.7600\nEpoch 100/100\n60/60 [==============================] - 5s 88ms/step - loss: 1.8685e-04 - acc: 1.0000 - val_loss: 1.0568 - val_acc: 0.7617\n","output_type":"stream"}]},{"cell_type":"code","source":"# train generator\nfrom tensorflow.keras.applications.xception import preprocess_input\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    brightness_range=[0.5,1.5],\n    fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='categorical')\n\n# validation generator\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='categorical')","metadata":{"id":"S1njCXVhN-cY","execution":{"iopub.status.busy":"2021-06-14T03:43:47.839829Z","iopub.execute_input":"2021-06-14T03:43:47.840196Z","iopub.status.idle":"2021-06-14T03:43:48.055029Z","shell.execute_reply.started":"2021-06-14T03:43:47.840156Z","shell.execute_reply":"2021-06-14T03:43:48.054249Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Found 1200 images belonging to 30 classes.\nFound 600 images belonging to 30 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.applications.xception import Xception\nconv_base = Xception(include_top=False,\n                  input_shape=(150, 150, 3),\n                  weights=None)\n\nconv_base.summary()","metadata":{"id":"qC94rIhyPHYj","execution":{"iopub.status.busy":"2021-06-14T03:43:48.056209Z","iopub.execute_input":"2021-06-14T03:43:48.056547Z","iopub.status.idle":"2021-06-14T03:43:48.795785Z","shell.execute_reply.started":"2021-06-14T03:43:48.056514Z","shell.execute_reply":"2021-06-14T03:43:48.790440Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Model: \"xception\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n__________________________________________________________________________________________________\nblock1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_3[0][0]                    \n__________________________________________________________________________________________________\nblock1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n__________________________________________________________________________________________________\nblock1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n__________________________________________________________________________________________________\nblock1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n__________________________________________________________________________________________________\nblock1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n__________________________________________________________________________________________________\nblock1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 36, 36, 128)  512         conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nadd_24 (Add)                    (None, 36, 36, 128)  0           block2_pool[0][0]                \n                                                                 batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nblock3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_24[0][0]                     \n__________________________________________________________________________________________________\nblock3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 18, 18, 256)  32768       add_24[0][0]                     \n__________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 18, 18, 256)  1024        conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nadd_25 (Add)                    (None, 18, 18, 256)  0           block3_pool[0][0]                \n                                                                 batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nblock4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_25[0][0]                     \n__________________________________________________________________________________________________\nblock4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 9, 9, 728)    186368      add_25[0][0]                     \n__________________________________________________________________________________________________\nblock4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 9, 9, 728)    2912        conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nadd_26 (Add)                    (None, 9, 9, 728)    0           block4_pool[0][0]                \n                                                                 batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nblock5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_26[0][0]                     \n__________________________________________________________________________________________________\nblock5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_27 (Add)                    (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n                                                                 add_26[0][0]                     \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_27[0][0]                     \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_28 (Add)                    (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n                                                                 add_27[0][0]                     \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_28[0][0]                     \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_29 (Add)                    (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n                                                                 add_28[0][0]                     \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_29[0][0]                     \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_30 (Add)                    (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n                                                                 add_29[0][0]                     \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_30[0][0]                     \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_31 (Add)                    (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n                                                                 add_30[0][0]                     \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_31[0][0]                     \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_32 (Add)                    (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n                                                                 add_31[0][0]                     \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_32[0][0]                     \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_33 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n                                                                 add_32[0][0]                     \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_33[0][0]                     \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_34 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n                                                                 add_33[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_34[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 5, 5, 1024)   745472      add_34[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 5, 5, 1024)   4096        conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nadd_35 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n                                                                 batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_35[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n==================================================================================================\nTotal params: 20,861,480\nTrainable params: 20,806,952\nNon-trainable params: 54,528\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(keras.layers.Flatten())\n# model.add(layers.Dense(128, activation='relu'))\nmodel.add(keras.layers.Dense(30, activation='softmax'))\n\n# model.summary()","metadata":{"id":"Y4W6aL1LPHYt","execution":{"iopub.status.busy":"2021-06-14T03:43:48.798491Z","iopub.execute_input":"2021-06-14T03:43:48.798740Z","iopub.status.idle":"2021-06-14T03:43:49.109425Z","shell.execute_reply.started":"2021-06-14T03:43:48.798715Z","shell.execute_reply":"2021-06-14T03:43:49.108584Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.build(input_shape=(None,150, 150, 3))\nmodel.summary()","metadata":{"id":"4El0nUAVPHYv","execution":{"iopub.status.busy":"2021-06-14T03:43:49.111496Z","iopub.execute_input":"2021-06-14T03:43:49.111844Z","iopub.status.idle":"2021-06-14T03:43:49.130001Z","shell.execute_reply.started":"2021-06-14T03:43:49.111795Z","shell.execute_reply":"2021-06-14T03:43:49.129271Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nxception (Functional)        (None, 5, 5, 2048)        20861480  \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 51200)             0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 30)                1536030   \n=================================================================\nTotal params: 22,397,510\nTrainable params: 22,342,982\nNon-trainable params: 54,528\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n              loss='categorical_crossentropy',\n              metrics=['acc'])\n\nhistory = model.fit(train_generator,\n                    epochs=100,\n                    validation_data=validation_generator\n                    )","metadata":{"id":"PjC7oYIePHYw","execution":{"iopub.status.busy":"2021-06-14T03:43:49.131113Z","iopub.execute_input":"2021-06-14T03:43:49.131439Z","iopub.status.idle":"2021-06-14T04:06:01.572469Z","shell.execute_reply.started":"2021-06-14T03:43:49.131404Z","shell.execute_reply":"2021-06-14T04:06:01.571638Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1/100\n60/60 [==============================] - 18s 233ms/step - loss: 3.3749 - acc: 0.0765 - val_loss: 3.4012 - val_acc: 0.0317\nEpoch 2/100\n60/60 [==============================] - 13s 222ms/step - loss: 2.9320 - acc: 0.1966 - val_loss: 3.4012 - val_acc: 0.0333\nEpoch 3/100\n60/60 [==============================] - 13s 218ms/step - loss: 2.6180 - acc: 0.2725 - val_loss: 3.4014 - val_acc: 0.0333\nEpoch 4/100\n60/60 [==============================] - 13s 216ms/step - loss: 2.4183 - acc: 0.3186 - val_loss: 3.4015 - val_acc: 0.0333\nEpoch 5/100\n60/60 [==============================] - 13s 223ms/step - loss: 2.2912 - acc: 0.3307 - val_loss: 3.4016 - val_acc: 0.0333\nEpoch 6/100\n60/60 [==============================] - 13s 219ms/step - loss: 2.1248 - acc: 0.3687 - val_loss: 3.3997 - val_acc: 0.0583\nEpoch 7/100\n60/60 [==============================] - 14s 225ms/step - loss: 2.0240 - acc: 0.4068 - val_loss: 3.3929 - val_acc: 0.0417\nEpoch 8/100\n60/60 [==============================] - 13s 217ms/step - loss: 2.0028 - acc: 0.4148 - val_loss: 3.3757 - val_acc: 0.0383\nEpoch 9/100\n60/60 [==============================] - 13s 215ms/step - loss: 1.8295 - acc: 0.4431 - val_loss: 3.3430 - val_acc: 0.0550\nEpoch 10/100\n60/60 [==============================] - 13s 223ms/step - loss: 1.8455 - acc: 0.4364 - val_loss: 3.2120 - val_acc: 0.0900\nEpoch 11/100\n60/60 [==============================] - 13s 217ms/step - loss: 1.6460 - acc: 0.5149 - val_loss: 3.0213 - val_acc: 0.1533\nEpoch 12/100\n60/60 [==============================] - 13s 224ms/step - loss: 1.6339 - acc: 0.5023 - val_loss: 2.7288 - val_acc: 0.2117\nEpoch 13/100\n60/60 [==============================] - 13s 216ms/step - loss: 1.7059 - acc: 0.4621 - val_loss: 2.4433 - val_acc: 0.2550\nEpoch 14/100\n60/60 [==============================] - 13s 216ms/step - loss: 1.6856 - acc: 0.4941 - val_loss: 2.0796 - val_acc: 0.3517\nEpoch 15/100\n60/60 [==============================] - 13s 222ms/step - loss: 1.6061 - acc: 0.5068 - val_loss: 1.8787 - val_acc: 0.4067\nEpoch 16/100\n60/60 [==============================] - 13s 218ms/step - loss: 1.5748 - acc: 0.5344 - val_loss: 1.8361 - val_acc: 0.4500\nEpoch 17/100\n60/60 [==============================] - 13s 224ms/step - loss: 1.6026 - acc: 0.5089 - val_loss: 1.8231 - val_acc: 0.4367\nEpoch 18/100\n60/60 [==============================] - 13s 217ms/step - loss: 1.4533 - acc: 0.5894 - val_loss: 1.8528 - val_acc: 0.4017\nEpoch 19/100\n60/60 [==============================] - 13s 216ms/step - loss: 1.5219 - acc: 0.5469 - val_loss: 1.8207 - val_acc: 0.4383\nEpoch 20/100\n60/60 [==============================] - 14s 225ms/step - loss: 1.4528 - acc: 0.5651 - val_loss: 1.7941 - val_acc: 0.4383\nEpoch 21/100\n60/60 [==============================] - 13s 217ms/step - loss: 1.4616 - acc: 0.5606 - val_loss: 1.8150 - val_acc: 0.4383\nEpoch 22/100\n60/60 [==============================] - 13s 222ms/step - loss: 1.4516 - acc: 0.5387 - val_loss: 1.7622 - val_acc: 0.4500\nEpoch 23/100\n60/60 [==============================] - 13s 216ms/step - loss: 1.3351 - acc: 0.5993 - val_loss: 1.7749 - val_acc: 0.4250\nEpoch 24/100\n60/60 [==============================] - 13s 216ms/step - loss: 1.3561 - acc: 0.5720 - val_loss: 1.8501 - val_acc: 0.4200\nEpoch 25/100\n60/60 [==============================] - 14s 224ms/step - loss: 1.2191 - acc: 0.6195 - val_loss: 1.8372 - val_acc: 0.4600\nEpoch 26/100\n60/60 [==============================] - 13s 216ms/step - loss: 1.3509 - acc: 0.5757 - val_loss: 1.8632 - val_acc: 0.4250\nEpoch 27/100\n60/60 [==============================] - 14s 226ms/step - loss: 1.2897 - acc: 0.6107 - val_loss: 1.8264 - val_acc: 0.4333\nEpoch 28/100\n60/60 [==============================] - 13s 216ms/step - loss: 1.2181 - acc: 0.6061 - val_loss: 1.7859 - val_acc: 0.4500\nEpoch 29/100\n60/60 [==============================] - 13s 219ms/step - loss: 1.2679 - acc: 0.5933 - val_loss: 2.0947 - val_acc: 0.4083\nEpoch 30/100\n60/60 [==============================] - 13s 220ms/step - loss: 1.1872 - acc: 0.6100 - val_loss: 1.9554 - val_acc: 0.4250\nEpoch 31/100\n60/60 [==============================] - 13s 217ms/step - loss: 1.2210 - acc: 0.6098 - val_loss: 1.8479 - val_acc: 0.4317\nEpoch 32/100\n60/60 [==============================] - 14s 225ms/step - loss: 1.1979 - acc: 0.6511 - val_loss: 1.9135 - val_acc: 0.4567\nEpoch 33/100\n60/60 [==============================] - 13s 222ms/step - loss: 0.9619 - acc: 0.6906 - val_loss: 1.8638 - val_acc: 0.4667\nEpoch 43/100\n60/60 [==============================] - 13s 216ms/step - loss: 0.9834 - acc: 0.6959 - val_loss: 1.8665 - val_acc: 0.4733\nEpoch 44/100\n60/60 [==============================] - 14s 233ms/step - loss: 0.9157 - acc: 0.6936 - val_loss: 1.8683 - val_acc: 0.4683\nEpoch 45/100\n60/60 [==============================] - 14s 232ms/step - loss: 0.9111 - acc: 0.7105 - val_loss: 2.1020 - val_acc: 0.4283\nEpoch 46/100\n60/60 [==============================] - 14s 236ms/step - loss: 0.9373 - acc: 0.6987 - val_loss: 1.9093 - val_acc: 0.4683\nEpoch 47/100\n60/60 [==============================] - 13s 223ms/step - loss: 0.9573 - acc: 0.6873 - val_loss: 1.8075 - val_acc: 0.4833\nEpoch 48/100\n60/60 [==============================] - 13s 217ms/step - loss: 0.9061 - acc: 0.7126 - val_loss: 2.0397 - val_acc: 0.4667\nEpoch 49/100\n60/60 [==============================] - 14s 227ms/step - loss: 0.9587 - acc: 0.6923 - val_loss: 1.6936 - val_acc: 0.5050\nEpoch 50/100\n60/60 [==============================] - 13s 217ms/step - loss: 0.8832 - acc: 0.7272 - val_loss: 1.8059 - val_acc: 0.4800\nEpoch 51/100\n60/60 [==============================] - 13s 219ms/step - loss: 0.9541 - acc: 0.6868 - val_loss: 1.9043 - val_acc: 0.4700\nEpoch 52/100\n60/60 [==============================] - 13s 221ms/step - loss: 0.9043 - acc: 0.6900 - val_loss: 2.2347 - val_acc: 0.4583\nEpoch 53/100\n60/60 [==============================] - 13s 216ms/step - loss: 0.8545 - acc: 0.7423 - val_loss: 1.9008 - val_acc: 0.5017\nEpoch 54/100\n60/60 [==============================] - 14s 229ms/step - loss: 0.8167 - acc: 0.7285 - val_loss: 1.8070 - val_acc: 0.4950\nEpoch 55/100\n60/60 [==============================] - 13s 217ms/step - loss: 0.8409 - acc: 0.7459 - val_loss: 1.9355 - val_acc: 0.4783\nEpoch 56/100\n60/60 [==============================] - 13s 222ms/step - loss: 0.8380 - acc: 0.7138 - val_loss: 1.9045 - val_acc: 0.4733\nEpoch 57/100\n60/60 [==============================] - 13s 215ms/step - loss: 0.8367 - acc: 0.7311 - val_loss: 1.6742 - val_acc: 0.5200\nEpoch 58/100\n60/60 [==============================] - 13s 216ms/step - loss: 0.8103 - acc: 0.7429 - val_loss: 1.8658 - val_acc: 0.5017\nEpoch 59/100\n60/60 [==============================] - 14s 223ms/step - loss: 0.8014 - acc: 0.7389 - val_loss: 1.9446 - val_acc: 0.5067\nEpoch 60/100\n60/60 [==============================] - 13s 217ms/step - loss: 0.7845 - acc: 0.7427 - val_loss: 1.8602 - val_acc: 0.5100\nEpoch 61/100\n60/60 [==============================] - 13s 224ms/step - loss: 0.8141 - acc: 0.7366 - val_loss: 1.9676 - val_acc: 0.4950\nEpoch 62/100\n60/60 [==============================] - 13s 217ms/step - loss: 0.7693 - acc: 0.7499 - val_loss: 2.0510 - val_acc: 0.4700\nEpoch 63/100\n60/60 [==============================] - 13s 223ms/step - loss: 0.7866 - acc: 0.7439 - val_loss: 1.8053 - val_acc: 0.5167\nEpoch 64/100\n60/60 [==============================] - 13s 223ms/step - loss: 0.7551 - acc: 0.7664 - val_loss: 1.8353 - val_acc: 0.5417\nEpoch 65/100\n60/60 [==============================] - 13s 216ms/step - loss: 0.7056 - acc: 0.7614 - val_loss: 1.9341 - val_acc: 0.5167\nEpoch 66/100\n60/60 [==============================] - 14s 224ms/step - loss: 0.7637 - acc: 0.7574 - val_loss: 2.1826 - val_acc: 0.4533\nEpoch 67/100\n60/60 [==============================] - 13s 218ms/step - loss: 0.7047 - acc: 0.7822 - val_loss: 1.7658 - val_acc: 0.5217\nEpoch 68/100\n60/60 [==============================] - 13s 220ms/step - loss: 0.7644 - acc: 0.7584 - val_loss: 1.8188 - val_acc: 0.5017\nEpoch 69/100\n60/60 [==============================] - 13s 223ms/step - loss: 0.7204 - acc: 0.7657 - val_loss: 1.8692 - val_acc: 0.5133\nEpoch 70/100\n60/60 [==============================] - 13s 215ms/step - loss: 0.6834 - acc: 0.7907 - val_loss: 1.9348 - val_acc: 0.4917\nEpoch 71/100\n60/60 [==============================] - 13s 224ms/step - loss: 0.7031 - acc: 0.7706 - val_loss: 1.7467 - val_acc: 0.5233\nEpoch 72/100\n60/60 [==============================] - 13s 214ms/step - loss: 0.6961 - acc: 0.7804 - val_loss: 1.7729 - val_acc: 0.5050\nEpoch 73/100\n60/60 [==============================] - 13s 219ms/step - loss: 0.6801 - acc: 0.7866 - val_loss: 1.9301 - val_acc: 0.5100\nEpoch 74/100\n60/60 [==============================] - 13s 224ms/step - loss: 0.8093 - acc: 0.7404 - val_loss: 1.8104 - val_acc: 0.5050\nEpoch 75/100\n60/60 [==============================] - 13s 217ms/step - loss: 0.6626 - acc: 0.7871 - val_loss: 1.9379 - val_acc: 0.5067\nEpoch 76/100\n60/60 [==============================] - 13s 224ms/step - loss: 0.5712 - acc: 0.8093 - val_loss: 1.9992 - val_acc: 0.5150\nEpoch 77/100\n60/60 [==============================] - 13s 214ms/step - loss: 0.6980 - acc: 0.7745 - val_loss: 1.9221 - val_acc: 0.5017\nEpoch 78/100\n60/60 [==============================] - 13s 223ms/step - loss: 0.5971 - acc: 0.8201 - val_loss: 1.8908 - val_acc: 0.5150\nEpoch 79/100\n60/60 [==============================] - 13s 219ms/step - loss: 0.6108 - acc: 0.8021 - val_loss: 2.0422 - val_acc: 0.4883\nEpoch 80/100\n60/60 [==============================] - 13s 216ms/step - loss: 0.6570 - acc: 0.7786 - val_loss: 1.8374 - val_acc: 0.5050\nEpoch 81/100\n60/60 [==============================] - 13s 224ms/step - loss: 0.5946 - acc: 0.8049 - val_loss: 2.0857 - val_acc: 0.4933\nEpoch 82/100\n60/60 [==============================] - 13s 216ms/step - loss: 0.6135 - acc: 0.7968 - val_loss: 1.8987 - val_acc: 0.5233\nEpoch 83/100\n60/60 [==============================] - 14s 225ms/step - loss: 0.5991 - acc: 0.7998 - val_loss: 1.8459 - val_acc: 0.5300\nEpoch 84/100\n60/60 [==============================] - 13s 214ms/step - loss: 0.6231 - acc: 0.7920 - val_loss: 2.1189 - val_acc: 0.5233\nEpoch 85/100\n60/60 [==============================] - 13s 215ms/step - loss: 0.5843 - acc: 0.8054 - val_loss: 1.7404 - val_acc: 0.5433\nEpoch 86/100\n60/60 [==============================] - 14s 226ms/step - loss: 0.5800 - acc: 0.8196 - val_loss: 1.9340 - val_acc: 0.5317\nEpoch 87/100\n60/60 [==============================] - 13s 219ms/step - loss: 0.6020 - acc: 0.8061 - val_loss: 2.2162 - val_acc: 0.4567\nEpoch 88/100\n60/60 [==============================] - 13s 224ms/step - loss: 0.6074 - acc: 0.7907 - val_loss: 2.0688 - val_acc: 0.5167\nEpoch 89/100\n60/60 [==============================] - 13s 215ms/step - loss: 0.5224 - acc: 0.8229 - val_loss: 2.3515 - val_acc: 0.4767\nEpoch 90/100\n60/60 [==============================] - 13s 216ms/step - loss: 0.5238 - acc: 0.8306 - val_loss: 1.8612 - val_acc: 0.5450\nEpoch 91/100\n60/60 [==============================] - 14s 225ms/step - loss: 0.5329 - acc: 0.8352 - val_loss: 1.9332 - val_acc: 0.5183\nEpoch 92/100\n60/60 [==============================] - 13s 215ms/step - loss: 0.5777 - acc: 0.8089 - val_loss: 2.0307 - val_acc: 0.4917\nEpoch 93/100\n60/60 [==============================] - 14s 228ms/step - loss: 0.5103 - acc: 0.8242 - val_loss: 2.0304 - val_acc: 0.5200\nEpoch 94/100\n60/60 [==============================] - 13s 214ms/step - loss: 0.4540 - acc: 0.8583 - val_loss: 2.0125 - val_acc: 0.5100\nEpoch 95/100\n60/60 [==============================] - 13s 216ms/step - loss: 0.5008 - acc: 0.8447 - val_loss: 1.8179 - val_acc: 0.5567\nEpoch 96/100\n60/60 [==============================] - 13s 223ms/step - loss: 0.4854 - acc: 0.8335 - val_loss: 2.0183 - val_acc: 0.5217\nEpoch 97/100\n60/60 [==============================] - 13s 216ms/step - loss: 0.4697 - acc: 0.8522 - val_loss: 2.1574 - val_acc: 0.5033\nEpoch 98/100\n60/60 [==============================] - 14s 227ms/step - loss: 0.4784 - acc: 0.8500 - val_loss: 1.7968 - val_acc: 0.5367\nEpoch 99/100\n60/60 [==============================] - 13s 216ms/step - loss: 0.4796 - acc: 0.8326 - val_loss: 1.9678 - val_acc: 0.5417\nEpoch 100/100\n60/60 [==============================] - 13s 220ms/step - loss: 0.4253 - acc: 0.8709 - val_loss: 1.8148 - val_acc: 0.5550\n","output_type":"stream"}]},{"cell_type":"code","source":"\nconv_base = Xception(include_top=False,\n                  input_shape=(150, 150, 3),\n                  weights='imagenet')\n\nconv_base.summary()","metadata":{"id":"GqLddlXVPHYx","execution":{"iopub.status.busy":"2021-06-14T04:06:01.574030Z","iopub.execute_input":"2021-06-14T04:06:01.574433Z","iopub.status.idle":"2021-06-14T04:06:02.701012Z","shell.execute_reply.started":"2021-06-14T04:06:01.574394Z","shell.execute_reply":"2021-06-14T04:06:02.700214Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Model: \"xception\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            [(None, 150, 150, 3) 0                                            \n__________________________________________________________________________________________________\nblock1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_4[0][0]                    \n__________________________________________________________________________________________________\nblock1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n__________________________________________________________________________________________________\nblock1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n__________________________________________________________________________________________________\nblock1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n__________________________________________________________________________________________________\nblock1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n__________________________________________________________________________________________________\nblock1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 36, 36, 128)  512         conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nadd_36 (Add)                    (None, 36, 36, 128)  0           block2_pool[0][0]                \n                                                                 batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nblock3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_36[0][0]                     \n__________________________________________________________________________________________________\nblock3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 18, 18, 256)  32768       add_36[0][0]                     \n__________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 18, 18, 256)  1024        conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nadd_37 (Add)                    (None, 18, 18, 256)  0           block3_pool[0][0]                \n                                                                 batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nblock4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_37[0][0]                     \n__________________________________________________________________________________________________\nblock4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 9, 9, 728)    186368      add_37[0][0]                     \n__________________________________________________________________________________________________\nblock4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 9, 9, 728)    2912        conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nadd_38 (Add)                    (None, 9, 9, 728)    0           block4_pool[0][0]                \n                                                                 batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nblock5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_38[0][0]                     \n__________________________________________________________________________________________________\nblock5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_39 (Add)                    (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n                                                                 add_38[0][0]                     \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_39[0][0]                     \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_40 (Add)                    (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n                                                                 add_39[0][0]                     \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_40[0][0]                     \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_41 (Add)                    (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n                                                                 add_40[0][0]                     \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_41[0][0]                     \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_42 (Add)                    (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n                                                                 add_41[0][0]                     \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_42[0][0]                     \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_43 (Add)                    (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n                                                                 add_42[0][0]                     \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_43[0][0]                     \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_44 (Add)                    (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n                                                                 add_43[0][0]                     \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_44[0][0]                     \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_45 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n                                                                 add_44[0][0]                     \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_45[0][0]                     \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_46 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n                                                                 add_45[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_46[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 5, 5, 1024)   745472      add_46[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 5, 5, 1024)   4096        conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nadd_47 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n                                                                 batch_normalization_15[0][0]     \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_47[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n==================================================================================================\nTotal params: 20,861,480\nTrainable params: 20,806,952\nNon-trainable params: 54,528\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(keras.layers.Flatten())\n# model.add(layers.Dense(128, activation='relu'))\nmodel.add(keras.layers.Dense(30, activation='softmax'))\n\n","metadata":{"id":"vph4ZXAMPHYy","execution":{"iopub.status.busy":"2021-06-14T04:06:02.702303Z","iopub.execute_input":"2021-06-14T04:06:02.702643Z","iopub.status.idle":"2021-06-14T04:06:03.013860Z","shell.execute_reply.started":"2021-06-14T04:06:02.702608Z","shell.execute_reply":"2021-06-14T04:06:03.013062Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"conv_base.trainable = False\n\n","metadata":{"id":"Ake4yrf6PHYz","execution":{"iopub.status.busy":"2021-06-14T04:06:03.014989Z","iopub.execute_input":"2021-06-14T04:06:03.015339Z","iopub.status.idle":"2021-06-14T04:06:03.025492Z","shell.execute_reply.started":"2021-06-14T04:06:03.015304Z","shell.execute_reply":"2021-06-14T04:06:03.024596Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model.build(input_shape=(None,150, 150, 3))\nmodel.summary()","metadata":{"id":"dpcbOE5EPHY0","execution":{"iopub.status.busy":"2021-06-14T04:06:03.026740Z","iopub.execute_input":"2021-06-14T04:06:03.027126Z","iopub.status.idle":"2021-06-14T04:06:03.045225Z","shell.execute_reply.started":"2021-06-14T04:06:03.027063Z","shell.execute_reply":"2021-06-14T04:06:03.044428Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nxception (Functional)        (None, 5, 5, 2048)        20861480  \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 51200)             0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 30)                1536030   \n=================================================================\nTotal params: 22,397,510\nTrainable params: 1,536,030\nNon-trainable params: 20,861,480\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n              loss='categorical_crossentropy',\n              metrics=['acc'])\n\nhistory = model.fit(train_generator,\n                    epochs=100,\n                    validation_data=validation_generator\n                    )","metadata":{"id":"brrcNW6pPHY2","execution":{"iopub.status.busy":"2021-06-14T04:06:03.046508Z","iopub.execute_input":"2021-06-14T04:06:03.046887Z","iopub.status.idle":"2021-06-14T04:24:19.089065Z","shell.execute_reply.started":"2021-06-14T04:06:03.046842Z","shell.execute_reply":"2021-06-14T04:24:19.088254Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/100\n60/60 [==============================] - 14s 194ms/step - loss: 3.2867 - acc: 0.1123 - val_loss: 2.5773 - val_acc: 0.2967\nEpoch 2/100\n60/60 [==============================] - 10s 172ms/step - loss: 2.1871 - acc: 0.4367 - val_loss: 2.1597 - val_acc: 0.4367\nEpoch 3/100\n60/60 [==============================] - 11s 188ms/step - loss: 1.6383 - acc: 0.5921 - val_loss: 1.8979 - val_acc: 0.5217\nEpoch 4/100\n60/60 [==============================] - 11s 184ms/step - loss: 1.3594 - acc: 0.6700 - val_loss: 1.7233 - val_acc: 0.5683\nEpoch 5/100\n60/60 [==============================] - 12s 191ms/step - loss: 1.2310 - acc: 0.6985 - val_loss: 1.6292 - val_acc: 0.5633\nEpoch 6/100\n60/60 [==============================] - 11s 185ms/step - loss: 1.0488 - acc: 0.7220 - val_loss: 1.5843 - val_acc: 0.5867\nEpoch 7/100\n60/60 [==============================] - 11s 175ms/step - loss: 0.9728 - acc: 0.7752 - val_loss: 1.5078 - val_acc: 0.5950\nEpoch 8/100\n60/60 [==============================] - 10s 174ms/step - loss: 0.8421 - acc: 0.7998 - val_loss: 1.4354 - val_acc: 0.6100\nEpoch 9/100\n60/60 [==============================] - 11s 185ms/step - loss: 0.7878 - acc: 0.8179 - val_loss: 1.3938 - val_acc: 0.6200\nEpoch 10/100\n60/60 [==============================] - 11s 174ms/step - loss: 0.8271 - acc: 0.8018 - val_loss: 1.3422 - val_acc: 0.6400\nEpoch 11/100\n60/60 [==============================] - 11s 177ms/step - loss: 0.7888 - acc: 0.7785 - val_loss: 1.3344 - val_acc: 0.6417\nEpoch 12/100\n60/60 [==============================] - 11s 186ms/step - loss: 0.7093 - acc: 0.8184 - val_loss: 1.2811 - val_acc: 0.6500\nEpoch 13/100\n60/60 [==============================] - 11s 180ms/step - loss: 0.7234 - acc: 0.8031 - val_loss: 1.2431 - val_acc: 0.6667\nEpoch 14/100\n60/60 [==============================] - 11s 178ms/step - loss: 0.7068 - acc: 0.7994 - val_loss: 1.2404 - val_acc: 0.6817\nEpoch 15/100\n60/60 [==============================] - 11s 191ms/step - loss: 0.6731 - acc: 0.8307 - val_loss: 1.2020 - val_acc: 0.6900\nEpoch 16/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.6320 - acc: 0.8404 - val_loss: 1.2127 - val_acc: 0.6733\nEpoch 17/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.5700 - acc: 0.8622 - val_loss: 1.1697 - val_acc: 0.6683\nEpoch 18/100\n60/60 [==============================] - 11s 191ms/step - loss: 0.6030 - acc: 0.8471 - val_loss: 1.1824 - val_acc: 0.6900\nEpoch 19/100\n60/60 [==============================] - 11s 180ms/step - loss: 0.5518 - acc: 0.8431 - val_loss: 1.1632 - val_acc: 0.6917\nEpoch 20/100\n60/60 [==============================] - 11s 187ms/step - loss: 0.5522 - acc: 0.8479 - val_loss: 1.1484 - val_acc: 0.7017\nEpoch 21/100\n60/60 [==============================] - 13s 215ms/step - loss: 0.5100 - acc: 0.8717 - val_loss: 1.1263 - val_acc: 0.7033\nEpoch 22/100\n60/60 [==============================] - 12s 200ms/step - loss: 0.5177 - acc: 0.8570 - val_loss: 1.1138 - val_acc: 0.6950\nEpoch 23/100\n60/60 [==============================] - 12s 201ms/step - loss: 0.4515 - acc: 0.8881 - val_loss: 1.0978 - val_acc: 0.7033\nEpoch 24/100\n60/60 [==============================] - 11s 189ms/step - loss: 0.4913 - acc: 0.8766 - val_loss: 1.0962 - val_acc: 0.7150\nEpoch 25/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.4194 - acc: 0.8932 - val_loss: 1.0708 - val_acc: 0.7250\nEpoch 26/100\n60/60 [==============================] - 11s 180ms/step - loss: 0.4645 - acc: 0.8846 - val_loss: 1.0687 - val_acc: 0.7100\nEpoch 27/100\n60/60 [==============================] - 11s 189ms/step - loss: 0.4564 - acc: 0.8934 - val_loss: 1.0603 - val_acc: 0.7167\nEpoch 28/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.4661 - acc: 0.8701 - val_loss: 1.0562 - val_acc: 0.7183\nEpoch 29/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.4386 - acc: 0.8810 - val_loss: 1.0559 - val_acc: 0.7167\nEpoch 30/100\n60/60 [==============================] - 11s 186ms/step - loss: 0.4357 - acc: 0.8936 - val_loss: 1.0404 - val_acc: 0.7217\nEpoch 31/100\n60/60 [==============================] - 11s 178ms/step - loss: 0.4003 - acc: 0.8898 - val_loss: 1.0537 - val_acc: 0.7283\nEpoch 32/100\n60/60 [==============================] - 11s 189ms/step - loss: 0.3764 - acc: 0.9087 - val_loss: 1.0613 - val_acc: 0.7150\nEpoch 33/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.3648 - acc: 0.9078 - val_loss: 1.0401 - val_acc: 0.7183\nEpoch 34/100\n60/60 [==============================] - 11s 181ms/step - loss: 0.4037 - acc: 0.8978 - val_loss: 1.0316 - val_acc: 0.7233\nEpoch 35/100\n60/60 [==============================] - 11s 189ms/step - loss: 0.4197 - acc: 0.8823 - val_loss: 1.0314 - val_acc: 0.7183\nEpoch 36/100\n60/60 [==============================] - 11s 180ms/step - loss: 0.3433 - acc: 0.8956 - val_loss: 1.0288 - val_acc: 0.7283\nEpoch 37/100\n60/60 [==============================] - 11s 178ms/step - loss: 0.3200 - acc: 0.9186 - val_loss: 1.0171 - val_acc: 0.7300\nEpoch 38/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.3921 - acc: 0.8979 - val_loss: 1.0376 - val_acc: 0.7233\nEpoch 39/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.3610 - acc: 0.8948 - val_loss: 1.0354 - val_acc: 0.7233\nEpoch 40/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.3428 - acc: 0.9110 - val_loss: 1.0286 - val_acc: 0.7250\nEpoch 41/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.3297 - acc: 0.9164 - val_loss: 1.0351 - val_acc: 0.7233\nEpoch 42/100\n60/60 [==============================] - 11s 185ms/step - loss: 0.3639 - acc: 0.9049 - val_loss: 1.0196 - val_acc: 0.7300\nEpoch 43/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.3331 - acc: 0.9088 - val_loss: 1.0113 - val_acc: 0.7317\nEpoch 44/100\n60/60 [==============================] - 11s 178ms/step - loss: 0.3143 - acc: 0.9220 - val_loss: 1.0333 - val_acc: 0.7250\nEpoch 45/100\n60/60 [==============================] - 11s 186ms/step - loss: 0.3198 - acc: 0.9193 - val_loss: 1.0219 - val_acc: 0.7250\nEpoch 46/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.3027 - acc: 0.9235 - val_loss: 1.0357 - val_acc: 0.7250\nEpoch 47/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.2843 - acc: 0.9297 - val_loss: 1.0228 - val_acc: 0.7233\nEpoch 48/100\n60/60 [==============================] - 11s 185ms/step - loss: 0.3403 - acc: 0.9113 - val_loss: 1.0020 - val_acc: 0.7267\nEpoch 49/100\n60/60 [==============================] - 11s 178ms/step - loss: 0.3221 - acc: 0.9108 - val_loss: 0.9977 - val_acc: 0.7233\nEpoch 50/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.3098 - acc: 0.9153 - val_loss: 0.9862 - val_acc: 0.7400\nEpoch 51/100\n60/60 [==============================] - 11s 186ms/step - loss: 0.2912 - acc: 0.9312 - val_loss: 0.9907 - val_acc: 0.7500\nEpoch 52/100\n60/60 [==============================] - 11s 178ms/step - loss: 0.2735 - acc: 0.9208 - val_loss: 0.9827 - val_acc: 0.7433\nEpoch 53/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.2551 - acc: 0.9355 - val_loss: 0.9949 - val_acc: 0.7350\nEpoch 54/100\n60/60 [==============================] - 11s 186ms/step - loss: 0.3034 - acc: 0.9242 - val_loss: 1.0002 - val_acc: 0.7317\nEpoch 55/100\n60/60 [==============================] - 11s 176ms/step - loss: 0.2914 - acc: 0.9272 - val_loss: 0.9814 - val_acc: 0.7367\nEpoch 56/100\n60/60 [==============================] - 11s 175ms/step - loss: 0.2342 - acc: 0.9330 - val_loss: 1.0106 - val_acc: 0.7300\nEpoch 57/100\n60/60 [==============================] - 11s 187ms/step - loss: 0.2847 - acc: 0.9291 - val_loss: 0.9869 - val_acc: 0.7350\nEpoch 58/100\n60/60 [==============================] - 10s 174ms/step - loss: 0.2754 - acc: 0.9225 - val_loss: 0.9972 - val_acc: 0.7317\nEpoch 59/100\n60/60 [==============================] - 11s 175ms/step - loss: 0.2928 - acc: 0.9241 - val_loss: 1.0010 - val_acc: 0.7267\nEpoch 60/100\n60/60 [==============================] - 11s 189ms/step - loss: 0.2597 - acc: 0.9308 - val_loss: 0.9914 - val_acc: 0.7333\nEpoch 61/100\n60/60 [==============================] - 10s 175ms/step - loss: 0.2286 - acc: 0.9415 - val_loss: 0.9965 - val_acc: 0.7350\nEpoch 62/100\n60/60 [==============================] - 10s 172ms/step - loss: 0.2872 - acc: 0.9261 - val_loss: 0.9965 - val_acc: 0.7400\nEpoch 63/100\n60/60 [==============================] - 11s 186ms/step - loss: 0.2605 - acc: 0.9280 - val_loss: 0.9638 - val_acc: 0.7317\nEpoch 64/100\n60/60 [==============================] - 11s 174ms/step - loss: 0.2479 - acc: 0.9287 - val_loss: 0.9921 - val_acc: 0.7350\nEpoch 65/100\n60/60 [==============================] - 11s 178ms/step - loss: 0.2547 - acc: 0.9249 - val_loss: 0.9896 - val_acc: 0.7317\nEpoch 66/100\n60/60 [==============================] - 11s 185ms/step - loss: 0.2296 - acc: 0.9436 - val_loss: 0.9775 - val_acc: 0.7367\nEpoch 67/100\n60/60 [==============================] - 11s 175ms/step - loss: 0.2918 - acc: 0.9179 - val_loss: 1.0058 - val_acc: 0.7217\nEpoch 68/100\n60/60 [==============================] - 11s 178ms/step - loss: 0.2371 - acc: 0.9365 - val_loss: 0.9819 - val_acc: 0.7300\nEpoch 69/100\n60/60 [==============================] - 13s 209ms/step - loss: 0.2592 - acc: 0.9145 - val_loss: 1.0007 - val_acc: 0.7333\nEpoch 70/100\n60/60 [==============================] - 10s 172ms/step - loss: 0.2247 - acc: 0.9277 - val_loss: 1.0100 - val_acc: 0.7267\nEpoch 71/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.2289 - acc: 0.9456 - val_loss: 0.9812 - val_acc: 0.7333\nEpoch 72/100\n60/60 [==============================] - 11s 177ms/step - loss: 0.2224 - acc: 0.9493 - val_loss: 1.0103 - val_acc: 0.7367\nEpoch 73/100\n60/60 [==============================] - 11s 176ms/step - loss: 0.2322 - acc: 0.9311 - val_loss: 1.0058 - val_acc: 0.7350\nEpoch 74/100\n60/60 [==============================] - 11s 185ms/step - loss: 0.2329 - acc: 0.9437 - val_loss: 0.9787 - val_acc: 0.7383\nEpoch 75/100\n60/60 [==============================] - 11s 175ms/step - loss: 0.2273 - acc: 0.9318 - val_loss: 0.9747 - val_acc: 0.7417\nEpoch 76/100\n60/60 [==============================] - 11s 177ms/step - loss: 0.2245 - acc: 0.9444 - val_loss: 0.9984 - val_acc: 0.7367\nEpoch 77/100\n60/60 [==============================] - 11s 186ms/step - loss: 0.2226 - acc: 0.9367 - val_loss: 0.9709 - val_acc: 0.7450\nEpoch 78/100\n60/60 [==============================] - 11s 176ms/step - loss: 0.2149 - acc: 0.9465 - val_loss: 1.0006 - val_acc: 0.7350\nEpoch 79/100\n60/60 [==============================] - 11s 178ms/step - loss: 0.1951 - acc: 0.9439 - val_loss: 0.9724 - val_acc: 0.7450\nEpoch 80/100\n60/60 [==============================] - 11s 185ms/step - loss: 0.2000 - acc: 0.9478 - val_loss: 0.9674 - val_acc: 0.7300\nEpoch 81/100\n60/60 [==============================] - 11s 178ms/step - loss: 0.1973 - acc: 0.9483 - val_loss: 0.9769 - val_acc: 0.7433\nEpoch 82/100\n60/60 [==============================] - 11s 176ms/step - loss: 0.2132 - acc: 0.9413 - val_loss: 0.9572 - val_acc: 0.7417\nEpoch 83/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.2222 - acc: 0.9421 - val_loss: 0.9849 - val_acc: 0.7517\nEpoch 84/100\n60/60 [==============================] - 11s 177ms/step - loss: 0.1927 - acc: 0.9505 - val_loss: 0.9917 - val_acc: 0.7450\nEpoch 85/100\n60/60 [==============================] - 11s 177ms/step - loss: 0.2326 - acc: 0.9358 - val_loss: 1.0077 - val_acc: 0.7467\nEpoch 86/100\n60/60 [==============================] - 11s 187ms/step - loss: 0.1635 - acc: 0.9630 - val_loss: 0.9865 - val_acc: 0.7433\nEpoch 87/100\n60/60 [==============================] - 11s 180ms/step - loss: 0.2186 - acc: 0.9339 - val_loss: 0.9758 - val_acc: 0.7433\nEpoch 88/100\n60/60 [==============================] - 11s 177ms/step - loss: 0.1804 - acc: 0.9594 - val_loss: 1.0068 - val_acc: 0.7417\nEpoch 89/100\n60/60 [==============================] - 11s 185ms/step - loss: 0.2177 - acc: 0.9545 - val_loss: 0.9717 - val_acc: 0.7483\nEpoch 90/100\n60/60 [==============================] - 11s 178ms/step - loss: 0.1758 - acc: 0.9630 - val_loss: 0.9770 - val_acc: 0.7517\nEpoch 91/100\n60/60 [==============================] - 11s 177ms/step - loss: 0.2154 - acc: 0.9399 - val_loss: 0.9747 - val_acc: 0.7517\nEpoch 92/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.1699 - acc: 0.9601 - val_loss: 0.9799 - val_acc: 0.7500\nEpoch 93/100\n60/60 [==============================] - 11s 181ms/step - loss: 0.1880 - acc: 0.9484 - val_loss: 0.9638 - val_acc: 0.7467\nEpoch 94/100\n60/60 [==============================] - 11s 176ms/step - loss: 0.1586 - acc: 0.9604 - val_loss: 0.9690 - val_acc: 0.7533\nEpoch 95/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.1920 - acc: 0.9473 - val_loss: 0.9375 - val_acc: 0.7500\nEpoch 96/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.1645 - acc: 0.9630 - val_loss: 0.9549 - val_acc: 0.7417\nEpoch 97/100\n60/60 [==============================] - 11s 176ms/step - loss: 0.1793 - acc: 0.9498 - val_loss: 0.9886 - val_acc: 0.7450\nEpoch 98/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.1598 - acc: 0.9629 - val_loss: 0.9901 - val_acc: 0.7433\nEpoch 99/100\n60/60 [==============================] - 11s 177ms/step - loss: 0.1713 - acc: 0.9563 - val_loss: 0.9893 - val_acc: 0.7383\nEpoch 100/100\n60/60 [==============================] - 11s 176ms/step - loss: 0.1712 - acc: 0.9570 - val_loss: 0.9802 - val_acc: 0.7450\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# conv_base = Xception(include_top=False,\n#                   input_shape=(150, 150, 3),\n#                   weights='imagenet')\n\n# conv_base.summary()","metadata":{"id":"SsvLcJ_kCXn_","execution":{"iopub.status.busy":"2021-06-14T04:24:19.090557Z","iopub.execute_input":"2021-06-14T04:24:19.090938Z","iopub.status.idle":"2021-06-14T04:24:19.096833Z","shell.execute_reply.started":"2021-06-14T04:24:19.090902Z","shell.execute_reply":"2021-06-14T04:24:19.096012Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"conv_base.trainable = True\n\nset_trainable = False\nfor layer in conv_base.layers:\n  if layer.name == 'block12_sepconv1':\n    set_trainable = True\n\n  if set_trainable:\n    layer.trainable = True\n  else:\n    layer.trainable = False\n\nmodel.summary()","metadata":{"id":"rheQzlh6CafG","execution":{"iopub.status.busy":"2021-06-14T04:24:19.098025Z","iopub.execute_input":"2021-06-14T04:24:19.098562Z","iopub.status.idle":"2021-06-14T04:24:19.128415Z","shell.execute_reply.started":"2021-06-14T04:24:19.098502Z","shell.execute_reply":"2021-06-14T04:24:19.127481Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nxception (Functional)        (None, 5, 5, 2048)        20861480  \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 51200)             0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 30)                1536030   \n=================================================================\nTotal params: 22,397,510\nTrainable params: 9,938,390\nNon-trainable params: 12,459,120\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n              loss='categorical_crossentropy',\n              metrics=['acc'])\n\nhistory = model.fit(train_generator,\n                    epochs=100,\n                    validation_data=validation_generator\n                    )","metadata":{"id":"1ndlJQ35DaMt","execution":{"iopub.status.busy":"2021-06-14T04:24:19.129651Z","iopub.execute_input":"2021-06-14T04:24:19.130035Z","iopub.status.idle":"2021-06-14T04:42:59.231735Z","shell.execute_reply.started":"2021-06-14T04:24:19.129999Z","shell.execute_reply":"2021-06-14T04:42:59.230933Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch 1/100\n60/60 [==============================] - 15s 205ms/step - loss: 1.3606 - acc: 0.7244 - val_loss: 1.0101 - val_acc: 0.7333\nEpoch 2/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.8758 - acc: 0.8361 - val_loss: 1.0025 - val_acc: 0.7367\nEpoch 3/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.6341 - acc: 0.8627 - val_loss: 0.9740 - val_acc: 0.7417\nEpoch 4/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.4707 - acc: 0.9100 - val_loss: 0.9249 - val_acc: 0.7433\nEpoch 5/100\n60/60 [==============================] - 11s 181ms/step - loss: 0.4430 - acc: 0.9008 - val_loss: 0.8690 - val_acc: 0.7650\nEpoch 6/100\n60/60 [==============================] - 11s 181ms/step - loss: 0.3741 - acc: 0.9045 - val_loss: 0.8340 - val_acc: 0.7867\nEpoch 7/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.3388 - acc: 0.9089 - val_loss: 0.8021 - val_acc: 0.7850\nEpoch 8/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.2787 - acc: 0.9316 - val_loss: 0.7924 - val_acc: 0.7883\nEpoch 9/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.2961 - acc: 0.9275 - val_loss: 0.7664 - val_acc: 0.7850\nEpoch 10/100\n60/60 [==============================] - 11s 189ms/step - loss: 0.2621 - acc: 0.9206 - val_loss: 0.7564 - val_acc: 0.7783\nEpoch 11/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.2069 - acc: 0.9532 - val_loss: 0.7383 - val_acc: 0.7900\nEpoch 12/100\n60/60 [==============================] - 11s 180ms/step - loss: 0.2162 - acc: 0.9423 - val_loss: 0.7347 - val_acc: 0.7983\nEpoch 13/100\n60/60 [==============================] - 11s 189ms/step - loss: 0.1709 - acc: 0.9570 - val_loss: 0.6992 - val_acc: 0.8017\nEpoch 14/100\n60/60 [==============================] - 11s 181ms/step - loss: 0.1883 - acc: 0.9486 - val_loss: 0.7032 - val_acc: 0.8050\nEpoch 15/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.1668 - acc: 0.9587 - val_loss: 0.6839 - val_acc: 0.8100\nEpoch 16/100\n60/60 [==============================] - 11s 185ms/step - loss: 0.1708 - acc: 0.9631 - val_loss: 0.6891 - val_acc: 0.8117\nEpoch 17/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.1638 - acc: 0.9577 - val_loss: 0.6601 - val_acc: 0.8067\nEpoch 18/100\n60/60 [==============================] - 11s 186ms/step - loss: 0.1600 - acc: 0.9593 - val_loss: 0.6635 - val_acc: 0.8167\nEpoch 19/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.1564 - acc: 0.9541 - val_loss: 0.6640 - val_acc: 0.8150\nEpoch 20/100\n60/60 [==============================] - 11s 187ms/step - loss: 0.1362 - acc: 0.9659 - val_loss: 0.6463 - val_acc: 0.8167\nEpoch 21/100\n60/60 [==============================] - 11s 188ms/step - loss: 0.1609 - acc: 0.9527 - val_loss: 0.6515 - val_acc: 0.8150\nEpoch 22/100\n60/60 [==============================] - 11s 180ms/step - loss: 0.1196 - acc: 0.9633 - val_loss: 0.6340 - val_acc: 0.8217\nEpoch 23/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.1098 - acc: 0.9698 - val_loss: 0.6457 - val_acc: 0.8150\nEpoch 24/100\n60/60 [==============================] - 12s 205ms/step - loss: 0.1064 - acc: 0.9716 - val_loss: 0.6123 - val_acc: 0.8250\nEpoch 25/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.1084 - acc: 0.9736 - val_loss: 0.6163 - val_acc: 0.8300\nEpoch 26/100\n60/60 [==============================] - 13s 210ms/step - loss: 0.1111 - acc: 0.9656 - val_loss: 0.6128 - val_acc: 0.8317\nEpoch 27/100\n60/60 [==============================] - 12s 198ms/step - loss: 0.0872 - acc: 0.9770 - val_loss: 0.6088 - val_acc: 0.8283\nEpoch 28/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0922 - acc: 0.9763 - val_loss: 0.6066 - val_acc: 0.8317\nEpoch 29/100\n60/60 [==============================] - 11s 180ms/step - loss: 0.1175 - acc: 0.9615 - val_loss: 0.6121 - val_acc: 0.8317\nEpoch 30/100\n60/60 [==============================] - 11s 191ms/step - loss: 0.0810 - acc: 0.9831 - val_loss: 0.6263 - val_acc: 0.8283\nEpoch 31/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0876 - acc: 0.9780 - val_loss: 0.5988 - val_acc: 0.8283\nEpoch 32/100\n60/60 [==============================] - 11s 181ms/step - loss: 0.1071 - acc: 0.9651 - val_loss: 0.6124 - val_acc: 0.8300\nEpoch 33/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.0646 - acc: 0.9847 - val_loss: 0.6060 - val_acc: 0.8317\nEpoch 34/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0770 - acc: 0.9809 - val_loss: 0.6046 - val_acc: 0.8317\nEpoch 35/100\n60/60 [==============================] - 11s 186ms/step - loss: 0.0669 - acc: 0.9848 - val_loss: 0.6242 - val_acc: 0.8333\nEpoch 36/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.0908 - acc: 0.9731 - val_loss: 0.5837 - val_acc: 0.8333\nEpoch 37/100\n60/60 [==============================] - 11s 185ms/step - loss: 0.0845 - acc: 0.9785 - val_loss: 0.5783 - val_acc: 0.8450\nEpoch 38/100\n60/60 [==============================] - 12s 192ms/step - loss: 0.0768 - acc: 0.9832 - val_loss: 0.5959 - val_acc: 0.8533\nEpoch 39/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0654 - acc: 0.9890 - val_loss: 0.5802 - val_acc: 0.8483\nEpoch 40/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.0586 - acc: 0.9862 - val_loss: 0.5791 - val_acc: 0.8483\nEpoch 41/100\n60/60 [==============================] - 12s 193ms/step - loss: 0.0525 - acc: 0.9899 - val_loss: 0.5637 - val_acc: 0.8517\nEpoch 42/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.0533 - acc: 0.9830 - val_loss: 0.5830 - val_acc: 0.8517\nEpoch 43/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0470 - acc: 0.9881 - val_loss: 0.5661 - val_acc: 0.8500\nEpoch 44/100\n60/60 [==============================] - 12s 192ms/step - loss: 0.0464 - acc: 0.9901 - val_loss: 0.5867 - val_acc: 0.8567\nEpoch 45/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.0557 - acc: 0.9848 - val_loss: 0.6014 - val_acc: 0.8500\nEpoch 46/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.0668 - acc: 0.9838 - val_loss: 0.5843 - val_acc: 0.8567\nEpoch 47/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.0495 - acc: 0.9854 - val_loss: 0.5768 - val_acc: 0.8533\nEpoch 48/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0462 - acc: 0.9907 - val_loss: 0.5804 - val_acc: 0.8450\nEpoch 49/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.0495 - acc: 0.9838 - val_loss: 0.5913 - val_acc: 0.8400\nEpoch 50/100\n60/60 [==============================] - 11s 192ms/step - loss: 0.0519 - acc: 0.9857 - val_loss: 0.5989 - val_acc: 0.8450\nEpoch 51/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0754 - acc: 0.9852 - val_loss: 0.5925 - val_acc: 0.8450\nEpoch 52/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.0469 - acc: 0.9911 - val_loss: 0.5755 - val_acc: 0.8533\nEpoch 53/100\n60/60 [==============================] - 11s 191ms/step - loss: 0.0520 - acc: 0.9895 - val_loss: 0.5737 - val_acc: 0.8467\nEpoch 54/100\n60/60 [==============================] - 11s 180ms/step - loss: 0.0644 - acc: 0.9794 - val_loss: 0.5874 - val_acc: 0.8533\nEpoch 55/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0403 - acc: 0.9939 - val_loss: 0.5692 - val_acc: 0.8533\nEpoch 56/100\n60/60 [==============================] - 11s 189ms/step - loss: 0.0297 - acc: 0.9965 - val_loss: 0.5957 - val_acc: 0.8433\nEpoch 57/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.0500 - acc: 0.9908 - val_loss: 0.5778 - val_acc: 0.8450\nEpoch 58/100\n60/60 [==============================] - 11s 185ms/step - loss: 0.0376 - acc: 0.9879 - val_loss: 0.5926 - val_acc: 0.8483\nEpoch 59/100\n60/60 [==============================] - 12s 192ms/step - loss: 0.0430 - acc: 0.9898 - val_loss: 0.5887 - val_acc: 0.8567\nEpoch 60/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.0350 - acc: 0.9938 - val_loss: 0.5983 - val_acc: 0.8483\nEpoch 61/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.0518 - acc: 0.9845 - val_loss: 0.6065 - val_acc: 0.8483\nEpoch 62/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.0261 - acc: 0.9961 - val_loss: 0.5990 - val_acc: 0.8467\nEpoch 63/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0300 - acc: 0.9918 - val_loss: 0.6082 - val_acc: 0.8417\nEpoch 64/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.0480 - acc: 0.9861 - val_loss: 0.5947 - val_acc: 0.8467\nEpoch 65/100\n60/60 [==============================] - 12s 194ms/step - loss: 0.0332 - acc: 0.9919 - val_loss: 0.5635 - val_acc: 0.8533\nEpoch 66/100\n60/60 [==============================] - 11s 187ms/step - loss: 0.0431 - acc: 0.9865 - val_loss: 0.5614 - val_acc: 0.8517\nEpoch 67/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.0304 - acc: 0.9941 - val_loss: 0.5338 - val_acc: 0.8633\nEpoch 68/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.0359 - acc: 0.9926 - val_loss: 0.5373 - val_acc: 0.8600\nEpoch 69/100\n60/60 [==============================] - 11s 186ms/step - loss: 0.0276 - acc: 0.9949 - val_loss: 0.5485 - val_acc: 0.8517\nEpoch 70/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0287 - acc: 0.9947 - val_loss: 0.5440 - val_acc: 0.8667\nEpoch 71/100\n60/60 [==============================] - 12s 195ms/step - loss: 0.0323 - acc: 0.9926 - val_loss: 0.5645 - val_acc: 0.8583\nEpoch 72/100\n60/60 [==============================] - 11s 185ms/step - loss: 0.0311 - acc: 0.9928 - val_loss: 0.5588 - val_acc: 0.8567\nEpoch 73/100\n60/60 [==============================] - 12s 194ms/step - loss: 0.0407 - acc: 0.9826 - val_loss: 0.5624 - val_acc: 0.8617\nEpoch 74/100\n60/60 [==============================] - 11s 184ms/step - loss: 0.0555 - acc: 0.9844 - val_loss: 0.5601 - val_acc: 0.8650\nEpoch 75/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0280 - acc: 0.9932 - val_loss: 0.5483 - val_acc: 0.8633\nEpoch 76/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.0272 - acc: 0.9969 - val_loss: 0.5237 - val_acc: 0.8667\nEpoch 77/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0394 - acc: 0.9892 - val_loss: 0.5615 - val_acc: 0.8667\nEpoch 78/100\n60/60 [==============================] - 11s 181ms/step - loss: 0.0254 - acc: 0.9922 - val_loss: 0.5777 - val_acc: 0.8633\nEpoch 79/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.0292 - acc: 0.9947 - val_loss: 0.5624 - val_acc: 0.8650\nEpoch 80/100\n60/60 [==============================] - 11s 180ms/step - loss: 0.0333 - acc: 0.9937 - val_loss: 0.5544 - val_acc: 0.8650\nEpoch 81/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.0221 - acc: 0.9961 - val_loss: 0.5673 - val_acc: 0.8633\nEpoch 82/100\n60/60 [==============================] - 12s 192ms/step - loss: 0.0329 - acc: 0.9919 - val_loss: 0.5786 - val_acc: 0.8600\nEpoch 83/100\n60/60 [==============================] - 11s 179ms/step - loss: 0.0186 - acc: 0.9965 - val_loss: 0.5688 - val_acc: 0.8717\nEpoch 84/100\n60/60 [==============================] - 11s 180ms/step - loss: 0.0390 - acc: 0.9836 - val_loss: 0.5673 - val_acc: 0.8617\nEpoch 85/100\n60/60 [==============================] - 12s 191ms/step - loss: 0.0297 - acc: 0.9905 - val_loss: 0.5487 - val_acc: 0.8583\nEpoch 86/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0248 - acc: 0.9938 - val_loss: 0.5541 - val_acc: 0.8600\nEpoch 87/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0354 - acc: 0.9885 - val_loss: 0.5587 - val_acc: 0.8650\nEpoch 88/100\n60/60 [==============================] - 12s 192ms/step - loss: 0.0277 - acc: 0.9906 - val_loss: 0.5545 - val_acc: 0.8650\nEpoch 89/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0169 - acc: 0.9979 - val_loss: 0.5571 - val_acc: 0.8617\nEpoch 90/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.0192 - acc: 0.9952 - val_loss: 0.5766 - val_acc: 0.8617\nEpoch 91/100\n60/60 [==============================] - 11s 191ms/step - loss: 0.0343 - acc: 0.9875 - val_loss: 0.5325 - val_acc: 0.8767\nEpoch 92/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0215 - acc: 0.9953 - val_loss: 0.5471 - val_acc: 0.8683\nEpoch 93/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0177 - acc: 0.9982 - val_loss: 0.5453 - val_acc: 0.8650\nEpoch 94/100\n60/60 [==============================] - 12s 192ms/step - loss: 0.0269 - acc: 0.9916 - val_loss: 0.5434 - val_acc: 0.8733\nEpoch 95/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0218 - acc: 0.9935 - val_loss: 0.5446 - val_acc: 0.8733\nEpoch 96/100\n60/60 [==============================] - 11s 183ms/step - loss: 0.0282 - acc: 0.9912 - val_loss: 0.5619 - val_acc: 0.8667\nEpoch 97/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.0131 - acc: 0.9971 - val_loss: 0.5506 - val_acc: 0.8700\nEpoch 98/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0223 - acc: 0.9916 - val_loss: 0.5691 - val_acc: 0.8650\nEpoch 99/100\n60/60 [==============================] - 11s 182ms/step - loss: 0.0209 - acc: 0.9976 - val_loss: 0.5710 - val_acc: 0.8667\nEpoch 100/100\n60/60 [==============================] - 11s 190ms/step - loss: 0.0242 - acc: 0.9922 - val_loss: 0.6014 - val_acc: 0.8583\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"p-RfMM6zDyKH"},"execution_count":null,"outputs":[]}]}