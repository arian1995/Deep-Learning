{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "HW11_Q3.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHxPOeB3YIeA"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-14T11:02:56.797772Z",
          "iopub.execute_input": "2021-06-14T11:02:56.798302Z",
          "iopub.status.idle": "2021-06-14T11:02:56.805876Z",
          "shell.execute_reply.started": "2021-06-14T11:02:56.798254Z",
          "shell.execute_reply": "2021-06-14T11:02:56.804817Z"
        },
        "trusted": true,
        "id": "GqgyXo2-YGIi"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGE7iQWMYbix"
      },
      "source": [
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHSXeI0Q59kR",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:02:56.808044Z",
          "iopub.execute_input": "2021-06-14T11:02:56.808946Z",
          "iopub.status.idle": "2021-06-14T11:02:57.032741Z",
          "shell.execute_reply.started": "2021-06-14T11:02:56.808787Z",
          "shell.execute_reply": "2021-06-14T11:02:57.030839Z"
        },
        "trusted": true,
        "outputId": "e87e2f34-c73d-4884-ec32-2ad7cd41fb44"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Rescales all images by 1/255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_dir = '../input/aid-mini/train'\n",
        "test_dir = '../input/aid-mini/test'\n",
        "# train generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,              # Target directory\n",
        "    target_size=(150, 150), # Resizes all images to 150 × 150\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# validation generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,         # Target directory\n",
        "    target_size=(150, 150), # Resizes all images to 150 × 150\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1200 images belonging to 30 classes.\n",
            "Found 600 images belonging to 30 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHeGddTiYvKb"
      },
      "source": [
        "## Without Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElJ3_VpFY_A1"
      },
      "source": [
        "### Random Weight Initialization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjM7NAVd72Zq",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:02:57.036735Z",
          "iopub.execute_input": "2021-06-14T11:02:57.037070Z",
          "iopub.status.idle": "2021-06-14T11:02:58.083552Z",
          "shell.execute_reply.started": "2021-06-14T11:02:57.037039Z",
          "shell.execute_reply": "2021-06-14T11:02:58.082064Z"
        },
        "trusted": true,
        "outputId": "90627572-e083-48aa-c2c1-e02c8fbee0ec"
      },
      "source": [
        "from keras.applications.xception import Xception\n",
        "conv_base = Xception(include_top=False,\n",
        "                  input_shape=(150, 150, 3),\n",
        "                  weights=None)\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 36, 36, 128)  512         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 18, 18, 256)  32768       add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 18, 18, 256)  1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 9, 9, 728)    186368      add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 9, 9, 728)    2912        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 5, 5, 1024)   745472      add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 5, 5, 1024)   4096        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIlB5TJQC3CS",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:02:58.086085Z",
          "iopub.execute_input": "2021-06-14T11:02:58.086576Z",
          "iopub.status.idle": "2021-06-14T11:02:58.527698Z",
          "shell.execute_reply.started": "2021-06-14T11:02:58.086502Z",
          "shell.execute_reply": "2021-06-14T11:02:58.526478Z"
        },
        "trusted": true
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(keras.layers.Flatten())\n",
        "# model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(30, activation='softmax'))\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UInSrBlzKjPz",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:02:58.529299Z",
          "iopub.execute_input": "2021-06-14T11:02:58.529744Z",
          "iopub.status.idle": "2021-06-14T11:02:58.556213Z",
          "shell.execute_reply.started": "2021-06-14T11:02:58.529697Z",
          "shell.execute_reply": "2021-06-14T11:02:58.555109Z"
        },
        "trusted": true,
        "outputId": "7fc1561d-5351-4927-aaf0-3fad7505102b"
      },
      "source": [
        "model.build(input_shape=(None,150, 150, 3))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Functional)        (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 30)                1536030   \n",
            "=================================================================\n",
            "Total params: 22,397,510\n",
            "Trainable params: 22,342,982\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yShHSOSSCd3c",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:02:58.557444Z",
          "iopub.execute_input": "2021-06-14T11:02:58.557832Z",
          "iopub.status.idle": "2021-06-14T11:19:12.695524Z",
          "shell.execute_reply.started": "2021-06-14T11:02:58.557775Z",
          "shell.execute_reply": "2021-06-14T11:19:12.694438Z"
        },
        "trusted": true,
        "outputId": "c248d154-fea4-40bd-c8ea-ddd4d152e0bb"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=100,\n",
        "                    validation_data=validation_generator\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 16s 182ms/step - loss: 3.2623 - acc: 0.0793 - val_loss: 3.4012 - val_acc: 0.0333\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 2.1452 - acc: 0.5502 - val_loss: 3.4014 - val_acc: 0.0333\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 1.5785 - acc: 0.7265 - val_loss: 3.4020 - val_acc: 0.0333\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 10s 161ms/step - loss: 1.1373 - acc: 0.8670 - val_loss: 3.4032 - val_acc: 0.0333\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 0.8430 - acc: 0.9003 - val_loss: 3.4061 - val_acc: 0.0333\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 0.6612 - acc: 0.9326 - val_loss: 3.4103 - val_acc: 0.0350\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.4646 - acc: 0.9577 - val_loss: 3.4174 - val_acc: 0.0383\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 10s 164ms/step - loss: 0.3274 - acc: 0.9844 - val_loss: 3.4354 - val_acc: 0.0517\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 9s 157ms/step - loss: 0.2708 - acc: 0.9829 - val_loss: 3.4589 - val_acc: 0.0483\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 0.2399 - acc: 0.9909 - val_loss: 3.4107 - val_acc: 0.0650\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.1789 - acc: 0.9937 - val_loss: 3.2320 - val_acc: 0.1000\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 0.1196 - acc: 0.9988 - val_loss: 2.8236 - val_acc: 0.1700\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 0.1189 - acc: 0.9943 - val_loss: 2.3493 - val_acc: 0.3150\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 10s 160ms/step - loss: 0.0885 - acc: 0.9969 - val_loss: 2.0857 - val_acc: 0.3667\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 10s 163ms/step - loss: 0.0713 - acc: 0.9993 - val_loss: 1.9011 - val_acc: 0.3967\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 10s 161ms/step - loss: 0.0778 - acc: 0.9989 - val_loss: 1.8004 - val_acc: 0.4650\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 10s 161ms/step - loss: 0.0669 - acc: 0.9978 - val_loss: 1.7462 - val_acc: 0.4700\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.0545 - acc: 0.9972 - val_loss: 1.7303 - val_acc: 0.4767\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0341 - acc: 1.0000 - val_loss: 1.7198 - val_acc: 0.4783\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 10s 160ms/step - loss: 0.0421 - acc: 0.9976 - val_loss: 1.7179 - val_acc: 0.4750\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.0371 - acc: 1.0000 - val_loss: 1.6967 - val_acc: 0.4850\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.0300 - acc: 0.9990 - val_loss: 1.7126 - val_acc: 0.4917\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0374 - acc: 0.9977 - val_loss: 1.7078 - val_acc: 0.4933\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.0390 - acc: 0.9948 - val_loss: 1.7309 - val_acc: 0.4817\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 10s 162ms/step - loss: 0.0232 - acc: 1.0000 - val_loss: 1.7192 - val_acc: 0.4850\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 0.0168 - acc: 0.9998 - val_loss: 1.7585 - val_acc: 0.4750\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 10s 163ms/step - loss: 0.0215 - acc: 0.9991 - val_loss: 1.6835 - val_acc: 0.5033\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 0.0195 - acc: 0.9991 - val_loss: 1.6906 - val_acc: 0.4917\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.0170 - acc: 1.0000 - val_loss: 1.7184 - val_acc: 0.4917\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 10s 164ms/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.6865 - val_acc: 0.5017\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 1.6701 - val_acc: 0.5033\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.6667 - val_acc: 0.5067\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 10s 163ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 1.6874 - val_acc: 0.4867\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 10s 163ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 1.6773 - val_acc: 0.5000\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 1.6742 - val_acc: 0.4983\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 10s 162ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 1.6778 - val_acc: 0.4967\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 10s 160ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 1.6682 - val_acc: 0.4967\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0120 - acc: 0.9990 - val_loss: 1.6734 - val_acc: 0.4967\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.6790 - val_acc: 0.4900\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 0.0124 - acc: 0.9997 - val_loss: 1.6782 - val_acc: 0.5083\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 10s 167ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.6632 - val_acc: 0.4983\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 10s 162ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.6726 - val_acc: 0.5083\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 9s 157ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.6808 - val_acc: 0.4833\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 1.6420 - val_acc: 0.5067\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 1.6941 - val_acc: 0.4767\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 10s 163ms/step - loss: 0.0104 - acc: 0.9957 - val_loss: 1.7247 - val_acc: 0.4833\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 10s 160ms/step - loss: 0.0061 - acc: 0.9998 - val_loss: 1.7197 - val_acc: 0.4867\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 1.6720 - val_acc: 0.5000\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 10s 168ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 1.6738 - val_acc: 0.5000\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 10s 163ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 1.6794 - val_acc: 0.5017\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 10s 161ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.6964 - val_acc: 0.5000\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 9s 156ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 1.6775 - val_acc: 0.5050\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 10s 164ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.6725 - val_acc: 0.5050\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.6682 - val_acc: 0.5067\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.6829 - val_acc: 0.4950\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 10s 163ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.6814 - val_acc: 0.5067\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 9s 156ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 1.6755 - val_acc: 0.5033\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 10s 161ms/step - loss: 0.0044 - acc: 0.9995 - val_loss: 1.7330 - val_acc: 0.4867\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 10s 160ms/step - loss: 0.0043 - acc: 0.9992 - val_loss: 1.7423 - val_acc: 0.4867\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.0182 - acc: 0.9950 - val_loss: 1.6935 - val_acc: 0.4883\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.7244 - val_acc: 0.4883\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 0.0065 - acc: 0.9996 - val_loss: 1.7652 - val_acc: 0.4667\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 0.0070 - acc: 0.9989 - val_loss: 1.7028 - val_acc: 0.4917\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 10s 162ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 1.6821 - val_acc: 0.4933\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.6812 - val_acc: 0.4950\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 10s 160ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.6801 - val_acc: 0.4883\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 11s 181ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.6803 - val_acc: 0.4867\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 10s 169ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.7715 - val_acc: 0.4767\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 9s 156ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 1.7319 - val_acc: 0.4733\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.7732 - val_acc: 0.4750\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 10s 161ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.7020 - val_acc: 0.4833\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 9s 157ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.7000 - val_acc: 0.4933\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 9s 157ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.6900 - val_acc: 0.4817\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 10s 168ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.7027 - val_acc: 0.4900\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 10s 171ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.7145 - val_acc: 0.4817\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 10s 160ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.7080 - val_acc: 0.4800\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 9s 157ms/step - loss: 7.7165e-04 - acc: 1.0000 - val_loss: 1.6940 - val_acc: 0.4850\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 10s 162ms/step - loss: 7.0272e-04 - acc: 1.0000 - val_loss: 1.6885 - val_acc: 0.4850\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 9s 157ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.6857 - val_acc: 0.4883\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 9s 157ms/step - loss: 7.1898e-04 - acc: 1.0000 - val_loss: 1.6969 - val_acc: 0.4900\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 10s 160ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.7116 - val_acc: 0.4817\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 7.8980e-04 - acc: 1.0000 - val_loss: 1.6831 - val_acc: 0.4967\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 10s 159ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.6847 - val_acc: 0.4967\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 10s 163ms/step - loss: 7.6432e-04 - acc: 1.0000 - val_loss: 1.7047 - val_acc: 0.5000\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 9s 157ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.7141 - val_acc: 0.4967\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 7.6514e-04 - acc: 1.0000 - val_loss: 1.6967 - val_acc: 0.4933\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 9s 157ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.7071 - val_acc: 0.4800\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 10s 163ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.7133 - val_acc: 0.4900\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 9s 157ms/step - loss: 8.4946e-04 - acc: 1.0000 - val_loss: 1.7009 - val_acc: 0.4800\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 9s 157ms/step - loss: 5.7140e-04 - acc: 1.0000 - val_loss: 1.7049 - val_acc: 0.4817\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 10s 169ms/step - loss: 7.1652e-04 - acc: 1.0000 - val_loss: 1.7249 - val_acc: 0.4933\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 10s 160ms/step - loss: 0.0070 - acc: 0.9976 - val_loss: 1.9252 - val_acc: 0.4467\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 9s 156ms/step - loss: 0.0158 - acc: 0.9981 - val_loss: 1.9794 - val_acc: 0.4333\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 10s 158ms/step - loss: 0.0231 - acc: 0.9952 - val_loss: 1.7673 - val_acc: 0.4517\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 10s 160ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.6997 - val_acc: 0.4750\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 10s 160ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.6886 - val_acc: 0.4883\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 1.8127 - val_acc: 0.4667\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 9s 158ms/step - loss: 0.0037 - acc: 0.9995 - val_loss: 2.2163 - val_acc: 0.3783\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 10s 167ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.8040 - val_acc: 0.4600\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 10s 161ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.7902 - val_acc: 0.4633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVt-3WSJZzTy"
      },
      "source": [
        "### Feature Extraction Using ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVLMbWsbMDA_",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:19:12.697588Z",
          "iopub.execute_input": "2021-06-14T11:19:12.698066Z",
          "iopub.status.idle": "2021-06-14T11:19:16.813511Z",
          "shell.execute_reply.started": "2021-06-14T11:19:12.698022Z",
          "shell.execute_reply": "2021-06-14T11:19:16.812060Z"
        },
        "trusted": true,
        "outputId": "acd52acb-fa54-4e17-9771-7411a1f72ad7"
      },
      "source": [
        "\n",
        "conv_base = Xception(include_top=False,\n",
        "                  input_shape=(150, 150, 3),\n",
        "                  weights='imagenet')\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n",
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 36, 36, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 18, 18, 256)  32768       add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 18, 18, 256)  1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 9, 9, 728)    186368      add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 9, 9, 728)    2912        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 5, 5, 1024)   745472      add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 5, 5, 1024)   4096        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foVQQgh2MDBV",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:19:16.817329Z",
          "iopub.execute_input": "2021-06-14T11:19:16.817619Z",
          "iopub.status.idle": "2021-06-14T11:19:17.243281Z",
          "shell.execute_reply.started": "2021-06-14T11:19:16.817590Z",
          "shell.execute_reply": "2021-06-14T11:19:17.242272Z"
        },
        "trusted": true
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(keras.layers.Flatten())\n",
        "# model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(30, activation='softmax'))\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z53cwb4Mqcq",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:19:17.245811Z",
          "iopub.execute_input": "2021-06-14T11:19:17.246204Z",
          "iopub.status.idle": "2021-06-14T11:19:17.258775Z",
          "shell.execute_reply.started": "2021-06-14T11:19:17.246163Z",
          "shell.execute_reply": "2021-06-14T11:19:17.257502Z"
        },
        "trusted": true
      },
      "source": [
        "conv_base.trainable = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awf2o4yOMDBX",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:19:17.260401Z",
          "iopub.execute_input": "2021-06-14T11:19:17.260883Z",
          "iopub.status.idle": "2021-06-14T11:19:17.283690Z",
          "shell.execute_reply.started": "2021-06-14T11:19:17.260840Z",
          "shell.execute_reply": "2021-06-14T11:19:17.282234Z"
        },
        "trusted": true,
        "outputId": "bc65f164-9af3-4ee7-e5ee-6937b2b5ecd8"
      },
      "source": [
        "model.build(input_shape=(None,150, 150, 3))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Functional)        (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30)                1536030   \n",
            "=================================================================\n",
            "Total params: 22,397,510\n",
            "Trainable params: 1,536,030\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xUIc_xEMDBZ",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:19:17.285924Z",
          "iopub.execute_input": "2021-06-14T11:19:17.286492Z",
          "iopub.status.idle": "2021-06-14T11:28:20.958206Z",
          "shell.execute_reply.started": "2021-06-14T11:19:17.286447Z",
          "shell.execute_reply": "2021-06-14T11:28:20.956165Z"
        },
        "trusted": true,
        "outputId": "d0b94479-9a0f-4ad8-c5c0-d1f5a571bb3c"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=100,\n",
        "                    validation_data=validation_generator\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 9s 108ms/step - loss: 3.2242 - acc: 0.1384 - val_loss: 2.3407 - val_acc: 0.4000\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 1.8078 - acc: 0.6414 - val_loss: 1.8634 - val_acc: 0.5483\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 6s 99ms/step - loss: 1.2273 - acc: 0.8086 - val_loss: 1.6339 - val_acc: 0.6000\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.9020 - acc: 0.8754 - val_loss: 1.4849 - val_acc: 0.6450\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.7272 - acc: 0.9107 - val_loss: 1.4087 - val_acc: 0.6467\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.5831 - acc: 0.9427 - val_loss: 1.3417 - val_acc: 0.6683\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.4918 - acc: 0.9637 - val_loss: 1.2976 - val_acc: 0.6833\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.4358 - acc: 0.9802 - val_loss: 1.2583 - val_acc: 0.6750\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 6s 101ms/step - loss: 0.4116 - acc: 0.9708 - val_loss: 1.2386 - val_acc: 0.6783\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.3371 - acc: 0.9878 - val_loss: 1.2158 - val_acc: 0.6817\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.3458 - acc: 0.9783 - val_loss: 1.1978 - val_acc: 0.6850\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.3121 - acc: 0.9835 - val_loss: 1.1868 - val_acc: 0.6867\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.2610 - acc: 0.9904 - val_loss: 1.1746 - val_acc: 0.6833\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.2546 - acc: 0.9959 - val_loss: 1.1674 - val_acc: 0.6900\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 6s 98ms/step - loss: 0.2580 - acc: 0.9914 - val_loss: 1.1577 - val_acc: 0.6867\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.2192 - acc: 0.9954 - val_loss: 1.1480 - val_acc: 0.6950\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.2086 - acc: 0.9975 - val_loss: 1.1437 - val_acc: 0.6900\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.2012 - acc: 0.9916 - val_loss: 1.1386 - val_acc: 0.6900\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.1832 - acc: 0.9952 - val_loss: 1.1330 - val_acc: 0.6883\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.1819 - acc: 0.9942 - val_loss: 1.1306 - val_acc: 0.6933\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 6s 99ms/step - loss: 0.1812 - acc: 0.9923 - val_loss: 1.1293 - val_acc: 0.6950\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.1664 - acc: 0.9972 - val_loss: 1.1242 - val_acc: 0.6917\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 5s 92ms/step - loss: 0.1652 - acc: 0.9951 - val_loss: 1.1227 - val_acc: 0.6950\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.1536 - acc: 0.9971 - val_loss: 1.1192 - val_acc: 0.6967\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.1420 - acc: 0.9973 - val_loss: 1.1175 - val_acc: 0.6967\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.1490 - acc: 0.9969 - val_loss: 1.1156 - val_acc: 0.6983\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 6s 99ms/step - loss: 0.1407 - acc: 0.9957 - val_loss: 1.1155 - val_acc: 0.6933\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.1597 - acc: 0.9962 - val_loss: 1.1137 - val_acc: 0.6967\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.1222 - acc: 0.9996 - val_loss: 1.1115 - val_acc: 0.6917\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.1380 - acc: 0.9992 - val_loss: 1.1119 - val_acc: 0.7017\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.1316 - acc: 0.9936 - val_loss: 1.1100 - val_acc: 0.7000\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.1092 - acc: 0.9990 - val_loss: 1.1121 - val_acc: 0.6933\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 6s 98ms/step - loss: 0.1179 - acc: 0.9972 - val_loss: 1.1097 - val_acc: 0.7000\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.1389 - acc: 0.9984 - val_loss: 1.1113 - val_acc: 0.6950\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.1194 - acc: 0.9986 - val_loss: 1.1101 - val_acc: 0.6983\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0947 - acc: 0.9987 - val_loss: 1.1110 - val_acc: 0.7000\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0949 - acc: 0.9981 - val_loss: 1.1118 - val_acc: 0.6983\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0966 - acc: 0.9978 - val_loss: 1.1120 - val_acc: 0.6983\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 6s 97ms/step - loss: 0.1218 - acc: 0.9954 - val_loss: 1.1120 - val_acc: 0.6983\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.1140 - acc: 0.9977 - val_loss: 1.1121 - val_acc: 0.6983\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0956 - acc: 0.9985 - val_loss: 1.1136 - val_acc: 0.7000\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.1107 - acc: 0.9987 - val_loss: 1.1141 - val_acc: 0.7000\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.1204 - acc: 0.9969 - val_loss: 1.1133 - val_acc: 0.6983\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.0988 - acc: 0.9964 - val_loss: 1.1157 - val_acc: 0.6983\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 6s 95ms/step - loss: 0.0977 - acc: 0.9992 - val_loss: 1.1162 - val_acc: 0.6983\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0874 - acc: 0.9957 - val_loss: 1.1169 - val_acc: 0.6983\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0828 - acc: 0.9949 - val_loss: 1.1164 - val_acc: 0.6983\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0849 - acc: 0.9987 - val_loss: 1.1189 - val_acc: 0.6983\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0854 - acc: 0.9968 - val_loss: 1.1178 - val_acc: 0.6983\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 0.0896 - acc: 0.9982 - val_loss: 1.1186 - val_acc: 0.6983\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.0930 - acc: 0.9982 - val_loss: 1.1212 - val_acc: 0.6983\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 0.0706 - acc: 0.9990 - val_loss: 1.1215 - val_acc: 0.6983\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0929 - acc: 0.9992 - val_loss: 1.1230 - val_acc: 0.6983\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0804 - acc: 0.9974 - val_loss: 1.1247 - val_acc: 0.7000\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0764 - acc: 0.9994 - val_loss: 1.1254 - val_acc: 0.6967\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0727 - acc: 0.9994 - val_loss: 1.1269 - val_acc: 0.6983\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0908 - acc: 0.9988 - val_loss: 1.1279 - val_acc: 0.7000\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 6s 98ms/step - loss: 0.0661 - acc: 0.9973 - val_loss: 1.1278 - val_acc: 0.7000\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0731 - acc: 0.9980 - val_loss: 1.1288 - val_acc: 0.7017\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.0641 - acc: 0.9991 - val_loss: 1.1318 - val_acc: 0.7017\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0763 - acc: 0.9981 - val_loss: 1.1332 - val_acc: 0.7017\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0742 - acc: 0.9986 - val_loss: 1.1328 - val_acc: 0.7000\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0677 - acc: 0.9989 - val_loss: 1.1362 - val_acc: 0.7033\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 6s 98ms/step - loss: 0.0649 - acc: 0.9987 - val_loss: 1.1364 - val_acc: 0.7017\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0787 - acc: 0.9975 - val_loss: 1.1387 - val_acc: 0.7000\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.0816 - acc: 0.9953 - val_loss: 1.1402 - val_acc: 0.7033\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0654 - acc: 0.9998 - val_loss: 1.1416 - val_acc: 0.7017\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 5s 92ms/step - loss: 0.0676 - acc: 0.9973 - val_loss: 1.1425 - val_acc: 0.7033\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0714 - acc: 0.9996 - val_loss: 1.1441 - val_acc: 0.7017\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 6s 97ms/step - loss: 0.0672 - acc: 0.9999 - val_loss: 1.1447 - val_acc: 0.7017\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0707 - acc: 0.9997 - val_loss: 1.1465 - val_acc: 0.7000\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 0.0633 - acc: 0.9995 - val_loss: 1.1480 - val_acc: 0.6983\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0468 - acc: 0.9993 - val_loss: 1.1517 - val_acc: 0.7000\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0509 - acc: 0.9998 - val_loss: 1.1523 - val_acc: 0.7000\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0594 - acc: 0.9993 - val_loss: 1.1536 - val_acc: 0.7017\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 6s 100ms/step - loss: 0.0596 - acc: 0.9988 - val_loss: 1.1543 - val_acc: 0.7033\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 0.0759 - acc: 0.9982 - val_loss: 1.1574 - val_acc: 0.7033\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0633 - acc: 0.9991 - val_loss: 1.1580 - val_acc: 0.7000\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0492 - acc: 0.9993 - val_loss: 1.1603 - val_acc: 0.7000\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0644 - acc: 0.9999 - val_loss: 1.1614 - val_acc: 0.7017\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0456 - acc: 1.0000 - val_loss: 1.1637 - val_acc: 0.6983\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 6s 98ms/step - loss: 0.0448 - acc: 1.0000 - val_loss: 1.1655 - val_acc: 0.7000\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0441 - acc: 1.0000 - val_loss: 1.1666 - val_acc: 0.6983\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0525 - acc: 1.0000 - val_loss: 1.1696 - val_acc: 0.6983\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0479 - acc: 1.0000 - val_loss: 1.1710 - val_acc: 0.6967\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0475 - acc: 1.0000 - val_loss: 1.1724 - val_acc: 0.6983\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0436 - acc: 1.0000 - val_loss: 1.1739 - val_acc: 0.6950\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 6s 95ms/step - loss: 0.0512 - acc: 1.0000 - val_loss: 1.1751 - val_acc: 0.7000\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 5s 87ms/step - loss: 0.0377 - acc: 1.0000 - val_loss: 1.1769 - val_acc: 0.6983\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0521 - acc: 1.0000 - val_loss: 1.1793 - val_acc: 0.6967\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0407 - acc: 1.0000 - val_loss: 1.1809 - val_acc: 0.6967\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 5s 86ms/step - loss: 0.0465 - acc: 1.0000 - val_loss: 1.1815 - val_acc: 0.6983\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0414 - acc: 1.0000 - val_loss: 1.1844 - val_acc: 0.6983\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 6s 94ms/step - loss: 0.0299 - acc: 1.0000 - val_loss: 1.1863 - val_acc: 0.6967\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0354 - acc: 1.0000 - val_loss: 1.1878 - val_acc: 0.7000\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0385 - acc: 1.0000 - val_loss: 1.1906 - val_acc: 0.6983\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 0.0432 - acc: 1.0000 - val_loss: 1.1911 - val_acc: 0.7000\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 5s 85ms/step - loss: 0.0282 - acc: 1.0000 - val_loss: 1.1931 - val_acc: 0.7000\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.0393 - acc: 1.0000 - val_loss: 1.1954 - val_acc: 0.7000\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 6s 103ms/step - loss: 0.0328 - acc: 1.0000 - val_loss: 1.1971 - val_acc: 0.6983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkRwv2RmwPgJ"
      },
      "source": [
        "### Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLcNrIKfJLhO",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:28:20.972304Z",
          "iopub.execute_input": "2021-06-14T11:28:20.972660Z",
          "iopub.status.idle": "2021-06-14T11:28:21.033281Z",
          "shell.execute_reply.started": "2021-06-14T11:28:20.972613Z",
          "shell.execute_reply": "2021-06-14T11:28:21.032114Z"
        },
        "trusted": true,
        "outputId": "e615cbbb-7ab3-4aad-ddc8-b0ce8bf0e5be"
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block12_sepconv1':\n",
        "    set_trainable = True\n",
        "\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Functional)        (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30)                1536030   \n",
            "=================================================================\n",
            "Total params: 22,397,510\n",
            "Trainable params: 9,938,390\n",
            "Non-trainable params: 12,459,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4ZitkSrJLhr",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:28:21.038613Z",
          "iopub.execute_input": "2021-06-14T11:28:21.041499Z",
          "iopub.status.idle": "2021-06-14T11:38:18.365444Z",
          "shell.execute_reply.started": "2021-06-14T11:28:21.041436Z",
          "shell.execute_reply": "2021-06-14T11:38:18.364457Z"
        },
        "trusted": true,
        "outputId": "c3a93c9f-b9a8-4248-9203-e0bcd3a09ab1"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=100,\n",
        "                    validation_data=validation_generator\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 12s 149ms/step - loss: 1.0952 - acc: 0.7945 - val_loss: 1.2940 - val_acc: 0.6917\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 7s 119ms/step - loss: 0.3281 - acc: 0.9530 - val_loss: 1.2859 - val_acc: 0.7100\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 7s 121ms/step - loss: 0.1685 - acc: 0.9887 - val_loss: 1.3058 - val_acc: 0.7067\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0901 - acc: 0.9969 - val_loss: 1.2602 - val_acc: 0.7100\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 6s 101ms/step - loss: 0.0574 - acc: 0.9984 - val_loss: 1.1995 - val_acc: 0.7150\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.0469 - acc: 1.0000 - val_loss: 1.1424 - val_acc: 0.7150\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 6s 94ms/step - loss: 0.0331 - acc: 0.9983 - val_loss: 1.1190 - val_acc: 0.7167\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.0319 - acc: 0.9976 - val_loss: 1.0969 - val_acc: 0.7217\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 0.0223 - acc: 0.9987 - val_loss: 1.0696 - val_acc: 0.7267\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 6s 99ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 1.0730 - val_acc: 0.7283\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 6s 91ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.0617 - val_acc: 0.7167\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0136 - acc: 0.9995 - val_loss: 1.0575 - val_acc: 0.7250\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 6s 91ms/step - loss: 0.0127 - acc: 0.9983 - val_loss: 1.0707 - val_acc: 0.7267\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 5s 88ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 1.0678 - val_acc: 0.7300\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 6s 92ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 1.0599 - val_acc: 0.7383\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 6s 103ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 1.0541 - val_acc: 0.7367\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 1.0533 - val_acc: 0.7383\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0559 - val_acc: 0.7383\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0508 - val_acc: 0.7417\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0422 - val_acc: 0.7433\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.0422 - val_acc: 0.7433\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 6s 103ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.0384 - val_acc: 0.7450\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 6s 92ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0359 - val_acc: 0.7483\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.0298 - val_acc: 0.7483\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.0333 - val_acc: 0.7467\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.0321 - val_acc: 0.7483\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 1.0338 - val_acc: 0.7500\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 7s 121ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.0401 - val_acc: 0.7517\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 7s 111ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.0377 - val_acc: 0.7483\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 9s 145ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 1.0368 - val_acc: 0.7533\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 8s 131ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.0431 - val_acc: 0.7550\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 7s 116ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.0738 - val_acc: 0.7383\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 6s 92ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.0683 - val_acc: 0.7433\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.0417 - val_acc: 0.7450\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0433 - val_acc: 0.7533\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 6s 100ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.0422 - val_acc: 0.7550\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 6s 101ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0435 - val_acc: 0.7517\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 7s 118ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.7550\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 6s 104ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.0436 - val_acc: 0.7500\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 7s 112ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0470 - val_acc: 0.7500\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 6s 108ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0460 - val_acc: 0.7550\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0495 - val_acc: 0.7550\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 6s 101ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0461 - val_acc: 0.7533\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0436 - val_acc: 0.7567\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 6s 94ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0395 - val_acc: 0.7533\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 9.6026e-04 - acc: 1.0000 - val_loss: 1.0409 - val_acc: 0.7533\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0444 - val_acc: 0.7567\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0363 - val_acc: 0.7550\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 6s 101ms/step - loss: 9.4689e-04 - acc: 1.0000 - val_loss: 1.0643 - val_acc: 0.7450\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 9.9250e-04 - acc: 1.0000 - val_loss: 1.0427 - val_acc: 0.7583\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 6s 95ms/step - loss: 9.3121e-04 - acc: 1.0000 - val_loss: 1.0494 - val_acc: 0.7583\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 7.2200e-04 - acc: 1.0000 - val_loss: 1.0473 - val_acc: 0.7600\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 7.9394e-04 - acc: 1.0000 - val_loss: 1.0448 - val_acc: 0.7600\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 7.3263e-04 - acc: 1.0000 - val_loss: 1.0472 - val_acc: 0.7633\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 5.7391e-04 - acc: 1.0000 - val_loss: 1.0459 - val_acc: 0.7600\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 6s 106ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0501 - val_acc: 0.7617\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 7s 113ms/step - loss: 7.9175e-04 - acc: 1.0000 - val_loss: 1.0518 - val_acc: 0.7650\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 6s 102ms/step - loss: 6.9547e-04 - acc: 1.0000 - val_loss: 1.0518 - val_acc: 0.7667\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 6s 101ms/step - loss: 6.0318e-04 - acc: 1.0000 - val_loss: 1.0519 - val_acc: 0.7683\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 6s 99ms/step - loss: 7.1147e-04 - acc: 1.0000 - val_loss: 1.0509 - val_acc: 0.7667\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 6s 97ms/step - loss: 6.3841e-04 - acc: 1.0000 - val_loss: 1.0501 - val_acc: 0.7650\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 6s 94ms/step - loss: 7.1252e-04 - acc: 1.0000 - val_loss: 1.0421 - val_acc: 0.7600\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 5.2761e-04 - acc: 1.0000 - val_loss: 1.0478 - val_acc: 0.7600\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 6s 94ms/step - loss: 5.0966e-04 - acc: 1.0000 - val_loss: 1.0464 - val_acc: 0.7600\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 5s 89ms/step - loss: 3.5564e-04 - acc: 1.0000 - val_loss: 1.0450 - val_acc: 0.7617\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 6s 95ms/step - loss: 5.0966e-04 - acc: 1.0000 - val_loss: 1.0502 - val_acc: 0.7600\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 6s 99ms/step - loss: 3.7994e-04 - acc: 1.0000 - val_loss: 1.0500 - val_acc: 0.7650\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 6s 94ms/step - loss: 5.7552e-04 - acc: 1.0000 - val_loss: 1.0439 - val_acc: 0.7650\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 3.2614e-04 - acc: 1.0000 - val_loss: 1.0532 - val_acc: 0.7650\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 6s 94ms/step - loss: 4.0966e-04 - acc: 1.0000 - val_loss: 1.0532 - val_acc: 0.7650\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 6.8205e-04 - acc: 1.0000 - val_loss: 1.0482 - val_acc: 0.7567\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 6s 95ms/step - loss: 3.6563e-04 - acc: 1.0000 - val_loss: 1.0403 - val_acc: 0.7600\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 6s 98ms/step - loss: 4.8992e-04 - acc: 1.0000 - val_loss: 1.0447 - val_acc: 0.7683\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 4.6504e-04 - acc: 1.0000 - val_loss: 1.0406 - val_acc: 0.7683\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 5s 90ms/step - loss: 3.9952e-04 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.7700\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 7s 113ms/step - loss: 2.7915e-04 - acc: 1.0000 - val_loss: 1.0463 - val_acc: 0.7717\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 3.2579e-04 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.7700\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 6s 105ms/step - loss: 3.0577e-04 - acc: 1.0000 - val_loss: 1.0379 - val_acc: 0.7700\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 6s 98ms/step - loss: 3.5352e-04 - acc: 1.0000 - val_loss: 1.0405 - val_acc: 0.7667\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 5s 91ms/step - loss: 2.4861e-04 - acc: 1.0000 - val_loss: 1.0422 - val_acc: 0.7700\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 6s 100ms/step - loss: 3.0438e-04 - acc: 1.0000 - val_loss: 1.0429 - val_acc: 0.7717\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 6s 95ms/step - loss: 2.7494e-04 - acc: 1.0000 - val_loss: 1.0421 - val_acc: 0.7717\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 6s 99ms/step - loss: 2.4206e-04 - acc: 1.0000 - val_loss: 1.0422 - val_acc: 0.7733\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 6s 103ms/step - loss: 2.5709e-04 - acc: 1.0000 - val_loss: 1.0432 - val_acc: 0.7717\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 6s 98ms/step - loss: 1.8332e-04 - acc: 1.0000 - val_loss: 1.0433 - val_acc: 0.7733\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 3.3627e-04 - acc: 1.0000 - val_loss: 1.0562 - val_acc: 0.7733\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 6s 99ms/step - loss: 2.7968e-04 - acc: 1.0000 - val_loss: 1.0539 - val_acc: 0.7750\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 6s 93ms/step - loss: 2.8666e-04 - acc: 1.0000 - val_loss: 1.0606 - val_acc: 0.7717\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 6s 100ms/step - loss: 2.0402e-04 - acc: 1.0000 - val_loss: 1.0672 - val_acc: 0.7683\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 6s 102ms/step - loss: 2.0926e-04 - acc: 1.0000 - val_loss: 1.0665 - val_acc: 0.7683\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 6s 97ms/step - loss: 2.0800e-04 - acc: 1.0000 - val_loss: 1.0647 - val_acc: 0.7733\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 6s 95ms/step - loss: 1.8134e-04 - acc: 1.0000 - val_loss: 1.0602 - val_acc: 0.7733\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 6s 97ms/step - loss: 2.2421e-04 - acc: 1.0000 - val_loss: 1.0625 - val_acc: 0.7717\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 6s 94ms/step - loss: 1.8981e-04 - acc: 1.0000 - val_loss: 1.0546 - val_acc: 0.7717\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 1.7898e-04 - acc: 1.0000 - val_loss: 1.0581 - val_acc: 0.7750\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 6s 104ms/step - loss: 1.7664e-04 - acc: 1.0000 - val_loss: 1.0700 - val_acc: 0.7783\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 6s 97ms/step - loss: 1.8644e-04 - acc: 1.0000 - val_loss: 1.0808 - val_acc: 0.7750\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 6s 98ms/step - loss: 2.2386e-04 - acc: 1.0000 - val_loss: 1.0664 - val_acc: 0.7717\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 6s 94ms/step - loss: 1.3445e-04 - acc: 1.0000 - val_loss: 1.0630 - val_acc: 0.7767\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 6s 102ms/step - loss: 1.2968e-04 - acc: 1.0000 - val_loss: 1.0621 - val_acc: 0.7783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JkRC9V9yblK"
      },
      "source": [
        "## With Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1njCXVhN-cY",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:38:18.367591Z",
          "iopub.execute_input": "2021-06-14T11:38:18.368169Z",
          "iopub.status.idle": "2021-06-14T11:38:18.587055Z",
          "shell.execute_reply.started": "2021-06-14T11:38:18.368123Z",
          "shell.execute_reply": "2021-06-14T11:38:18.586074Z"
        },
        "trusted": true,
        "outputId": "9f405441-aecd-46d6-acb6-ba41dd12344a"
      },
      "source": [
        "# train generator\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.5,1.5],\n",
        "    fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# validation generator\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1200 images belonging to 30 classes.\n",
            "Found 600 images belonging to 30 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii0q-3QjyoKO"
      },
      "source": [
        "### Random Weight Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC94rIhyPHYj",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:38:18.590402Z",
          "iopub.execute_input": "2021-06-14T11:38:18.590686Z",
          "iopub.status.idle": "2021-06-14T11:38:20.030284Z",
          "shell.execute_reply.started": "2021-06-14T11:38:18.590659Z",
          "shell.execute_reply": "2021-06-14T11:38:20.029065Z"
        },
        "trusted": true,
        "outputId": "eff2c914-7c5b-40f1-d3b9-bb348f424ead"
      },
      "source": [
        "from keras.applications.xception import Xception\n",
        "conv_base = Xception(include_top=False,\n",
        "                  input_shape=(150, 150, 3),\n",
        "                  weights=None)\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 36, 36, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 18, 18, 256)  32768       add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 18, 18, 256)  1024        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 9, 9, 728)    186368      add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 9, 9, 728)    2912        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 5, 5, 1024)   745472      add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 5, 5, 1024)   4096        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4W6aL1LPHYt",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:38:20.032156Z",
          "iopub.execute_input": "2021-06-14T11:38:20.032585Z",
          "iopub.status.idle": "2021-06-14T11:38:20.463849Z",
          "shell.execute_reply.started": "2021-06-14T11:38:20.032543Z",
          "shell.execute_reply": "2021-06-14T11:38:20.462795Z"
        },
        "trusted": true
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(keras.layers.Flatten())\n",
        "# model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(30, activation='softmax'))\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4El0nUAVPHYv",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:38:20.465448Z",
          "iopub.execute_input": "2021-06-14T11:38:20.465966Z",
          "iopub.status.idle": "2021-06-14T11:38:20.490898Z",
          "shell.execute_reply.started": "2021-06-14T11:38:20.465906Z",
          "shell.execute_reply": "2021-06-14T11:38:20.489404Z"
        },
        "trusted": true,
        "outputId": "0c33bef2-de85-4d4b-cd95-20e718f9a599"
      },
      "source": [
        "model.build(input_shape=(None,150, 150, 3))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Functional)        (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 30)                1536030   \n",
            "=================================================================\n",
            "Total params: 22,397,510\n",
            "Trainable params: 22,342,982\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjC7oYIePHYw",
        "execution": {
          "iopub.status.busy": "2021-06-14T11:38:20.492724Z",
          "iopub.execute_input": "2021-06-14T11:38:20.493189Z",
          "iopub.status.idle": "2021-06-14T12:03:27.462708Z",
          "shell.execute_reply.started": "2021-06-14T11:38:20.493148Z",
          "shell.execute_reply": "2021-06-14T12:03:27.461546Z"
        },
        "trusted": true,
        "outputId": "b23d6473-f852-4e04-e3a8-6e8f766adb36"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=100,\n",
        "                    validation_data=validation_generator\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 22s 283ms/step - loss: 3.4258 - acc: 0.0544 - val_loss: 3.4012 - val_acc: 0.0333\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 15s 252ms/step - loss: 2.9634 - acc: 0.1929 - val_loss: 3.4012 - val_acc: 0.0333\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 16s 259ms/step - loss: 2.6543 - acc: 0.2764 - val_loss: 3.4014 - val_acc: 0.0333\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 15s 246ms/step - loss: 2.4360 - acc: 0.3181 - val_loss: 3.4015 - val_acc: 0.0333\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 15s 256ms/step - loss: 2.2736 - acc: 0.3323 - val_loss: 3.4017 - val_acc: 0.0333\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 15s 250ms/step - loss: 2.1362 - acc: 0.3852 - val_loss: 3.4013 - val_acc: 0.0333\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 15s 255ms/step - loss: 2.0019 - acc: 0.4072 - val_loss: 3.3957 - val_acc: 0.0333\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 15s 250ms/step - loss: 2.0386 - acc: 0.3839 - val_loss: 3.3872 - val_acc: 0.0333\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 15s 258ms/step - loss: 1.9990 - acc: 0.4026 - val_loss: 3.3499 - val_acc: 0.0383\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 15s 246ms/step - loss: 1.9006 - acc: 0.4574 - val_loss: 3.2340 - val_acc: 0.0567\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 16s 262ms/step - loss: 1.7876 - acc: 0.4613 - val_loss: 3.0047 - val_acc: 0.1217\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 15s 246ms/step - loss: 1.8221 - acc: 0.4368 - val_loss: 2.6353 - val_acc: 0.2433\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 15s 249ms/step - loss: 1.7020 - acc: 0.5024 - val_loss: 2.2632 - val_acc: 0.2967\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 15s 245ms/step - loss: 1.7057 - acc: 0.4761 - val_loss: 1.9971 - val_acc: 0.3950\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 15s 241ms/step - loss: 1.6059 - acc: 0.5055 - val_loss: 1.8893 - val_acc: 0.4233\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 15s 257ms/step - loss: 1.5934 - acc: 0.5028 - val_loss: 1.8981 - val_acc: 0.4183\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 15s 249ms/step - loss: 1.5415 - acc: 0.5252 - val_loss: 1.7859 - val_acc: 0.4450\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 15s 253ms/step - loss: 1.5404 - acc: 0.5291 - val_loss: 1.8532 - val_acc: 0.4250\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 15s 250ms/step - loss: 1.4277 - acc: 0.5619 - val_loss: 1.7944 - val_acc: 0.4350\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 15s 251ms/step - loss: 1.4524 - acc: 0.5451 - val_loss: 1.8826 - val_acc: 0.4233\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 15s 242ms/step - loss: 1.4465 - acc: 0.5547 - val_loss: 1.7690 - val_acc: 0.4650\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 15s 255ms/step - loss: 1.4636 - acc: 0.5501 - val_loss: 1.8444 - val_acc: 0.4400\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 15s 243ms/step - loss: 1.3181 - acc: 0.6027 - val_loss: 1.8112 - val_acc: 0.4483\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 15s 246ms/step - loss: 1.4146 - acc: 0.5635 - val_loss: 1.8393 - val_acc: 0.4683\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 15s 250ms/step - loss: 1.3274 - acc: 0.6027 - val_loss: 1.8164 - val_acc: 0.4417\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 15s 242ms/step - loss: 1.2892 - acc: 0.5989 - val_loss: 1.8041 - val_acc: 0.4733\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 15s 256ms/step - loss: 1.2485 - acc: 0.6131 - val_loss: 1.9424 - val_acc: 0.4050\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 15s 245ms/step - loss: 1.1679 - acc: 0.6383 - val_loss: 1.8884 - val_acc: 0.4400\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 15s 245ms/step - loss: 1.1929 - acc: 0.6383 - val_loss: 2.0061 - val_acc: 0.4400\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 15s 248ms/step - loss: 1.2211 - acc: 0.6433 - val_loss: 1.8754 - val_acc: 0.4600\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 15s 242ms/step - loss: 1.1841 - acc: 0.6215 - val_loss: 1.7645 - val_acc: 0.4650\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 15s 251ms/step - loss: 1.1738 - acc: 0.6122 - val_loss: 1.8295 - val_acc: 0.4500\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 15s 247ms/step - loss: 1.1033 - acc: 0.6413 - val_loss: 1.8605 - val_acc: 0.4883\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 15s 250ms/step - loss: 1.1226 - acc: 0.6401 - val_loss: 2.0462 - val_acc: 0.4517\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 14s 240ms/step - loss: 1.0799 - acc: 0.6444 - val_loss: 1.7699 - val_acc: 0.4867\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 15s 255ms/step - loss: 1.1049 - acc: 0.6391 - val_loss: 1.9025 - val_acc: 0.4767\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 14s 240ms/step - loss: 1.0291 - acc: 0.6672 - val_loss: 2.2052 - val_acc: 0.4317\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 15s 250ms/step - loss: 1.0121 - acc: 0.6963 - val_loss: 1.6938 - val_acc: 0.5150\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 15s 242ms/step - loss: 1.0761 - acc: 0.6478 - val_loss: 2.4286 - val_acc: 0.4033\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 15s 243ms/step - loss: 1.0095 - acc: 0.6704 - val_loss: 1.9181 - val_acc: 0.4533\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 15s 250ms/step - loss: 0.9961 - acc: 0.6968 - val_loss: 1.8644 - val_acc: 0.4733\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 14s 240ms/step - loss: 1.0374 - acc: 0.6764 - val_loss: 1.6786 - val_acc: 0.5033\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 15s 253ms/step - loss: 0.9933 - acc: 0.6780 - val_loss: 1.8121 - val_acc: 0.5000\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 15s 245ms/step - loss: 0.9870 - acc: 0.6965 - val_loss: 2.0100 - val_acc: 0.4700\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 15s 248ms/step - loss: 0.9286 - acc: 0.7266 - val_loss: 1.9178 - val_acc: 0.4983\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 14s 240ms/step - loss: 0.9227 - acc: 0.7036 - val_loss: 1.7398 - val_acc: 0.5083\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 15s 252ms/step - loss: 0.9250 - acc: 0.7120 - val_loss: 1.8895 - val_acc: 0.4600\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 14s 240ms/step - loss: 0.8871 - acc: 0.7314 - val_loss: 2.1188 - val_acc: 0.4700\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 15s 252ms/step - loss: 0.9395 - acc: 0.6847 - val_loss: 2.2599 - val_acc: 0.4433\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 15s 250ms/step - loss: 0.8946 - acc: 0.7071 - val_loss: 1.9270 - val_acc: 0.4700\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 15s 254ms/step - loss: 0.8590 - acc: 0.7108 - val_loss: 1.9122 - val_acc: 0.4817\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 15s 247ms/step - loss: 0.8357 - acc: 0.7378 - val_loss: 2.2027 - val_acc: 0.4517\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 15s 247ms/step - loss: 0.8821 - acc: 0.7165 - val_loss: 1.8869 - val_acc: 0.4933\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 15s 251ms/step - loss: 0.7618 - acc: 0.7696 - val_loss: 1.7958 - val_acc: 0.4917\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 15s 248ms/step - loss: 0.7993 - acc: 0.7295 - val_loss: 1.9351 - val_acc: 0.4850\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 15s 251ms/step - loss: 0.8028 - acc: 0.7343 - val_loss: 1.7675 - val_acc: 0.5200\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 15s 244ms/step - loss: 0.8021 - acc: 0.7522 - val_loss: 1.8004 - val_acc: 0.5167\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 15s 257ms/step - loss: 0.8234 - acc: 0.7189 - val_loss: 1.9638 - val_acc: 0.5100\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 15s 243ms/step - loss: 0.8043 - acc: 0.7378 - val_loss: 1.9540 - val_acc: 0.4917\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 15s 251ms/step - loss: 0.7365 - acc: 0.7559 - val_loss: 1.8697 - val_acc: 0.5233\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 15s 244ms/step - loss: 0.6784 - acc: 0.7697 - val_loss: 2.1440 - val_acc: 0.4917\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 15s 257ms/step - loss: 0.7629 - acc: 0.7559 - val_loss: 1.7960 - val_acc: 0.5183\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 15s 245ms/step - loss: 0.7655 - acc: 0.7374 - val_loss: 1.8129 - val_acc: 0.5083\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 15s 254ms/step - loss: 0.7304 - acc: 0.7763 - val_loss: 1.9813 - val_acc: 0.5100\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 15s 242ms/step - loss: 0.7772 - acc: 0.7455 - val_loss: 1.9228 - val_acc: 0.5183\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 15s 246ms/step - loss: 0.6790 - acc: 0.7829 - val_loss: 2.0564 - val_acc: 0.4850\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 15s 250ms/step - loss: 0.7609 - acc: 0.7632 - val_loss: 1.9494 - val_acc: 0.5083\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 15s 248ms/step - loss: 0.7049 - acc: 0.7983 - val_loss: 1.9202 - val_acc: 0.4900\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 16s 269ms/step - loss: 0.6869 - acc: 0.7683 - val_loss: 1.7115 - val_acc: 0.5700\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 15s 257ms/step - loss: 0.7099 - acc: 0.7674 - val_loss: 1.9395 - val_acc: 0.5250\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 15s 253ms/step - loss: 0.6249 - acc: 0.8058 - val_loss: 1.8174 - val_acc: 0.5100\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 14s 240ms/step - loss: 0.6857 - acc: 0.7838 - val_loss: 1.8659 - val_acc: 0.5200\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 15s 251ms/step - loss: 0.6963 - acc: 0.7934 - val_loss: 2.0652 - val_acc: 0.5150\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 15s 245ms/step - loss: 0.6705 - acc: 0.7703 - val_loss: 1.8648 - val_acc: 0.5400\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 15s 257ms/step - loss: 0.5834 - acc: 0.8137 - val_loss: 1.8896 - val_acc: 0.5233\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 15s 244ms/step - loss: 0.6040 - acc: 0.8169 - val_loss: 1.8440 - val_acc: 0.5250\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 16s 262ms/step - loss: 0.6318 - acc: 0.7961 - val_loss: 2.0221 - val_acc: 0.4883\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 15s 242ms/step - loss: 0.6099 - acc: 0.8063 - val_loss: 1.8422 - val_acc: 0.5400\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 14s 241ms/step - loss: 0.5193 - acc: 0.8433 - val_loss: 1.9101 - val_acc: 0.5467\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 15s 255ms/step - loss: 0.6102 - acc: 0.7976 - val_loss: 2.1578 - val_acc: 0.5233\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 15s 241ms/step - loss: 0.5808 - acc: 0.8032 - val_loss: 1.8309 - val_acc: 0.5400\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 15s 252ms/step - loss: 0.5609 - acc: 0.8208 - val_loss: 1.6815 - val_acc: 0.5500\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 15s 241ms/step - loss: 0.5581 - acc: 0.8100 - val_loss: 1.7818 - val_acc: 0.5400\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 15s 252ms/step - loss: 0.6327 - acc: 0.7971 - val_loss: 1.7732 - val_acc: 0.5333\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 15s 245ms/step - loss: 0.5169 - acc: 0.8351 - val_loss: 1.9786 - val_acc: 0.5117\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 15s 252ms/step - loss: 0.5193 - acc: 0.8263 - val_loss: 1.8646 - val_acc: 0.5450\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 15s 241ms/step - loss: 0.5489 - acc: 0.8200 - val_loss: 1.7855 - val_acc: 0.5500\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 16s 259ms/step - loss: 0.5153 - acc: 0.8191 - val_loss: 2.1316 - val_acc: 0.5050\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 15s 242ms/step - loss: 0.5033 - acc: 0.8368 - val_loss: 2.0921 - val_acc: 0.5317\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 15s 241ms/step - loss: 0.5311 - acc: 0.8262 - val_loss: 1.8990 - val_acc: 0.5150\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 15s 256ms/step - loss: 0.4912 - acc: 0.8503 - val_loss: 1.7240 - val_acc: 0.5600\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 15s 241ms/step - loss: 0.5092 - acc: 0.8292 - val_loss: 2.0050 - val_acc: 0.5183\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 15s 253ms/step - loss: 0.4774 - acc: 0.8422 - val_loss: 1.9386 - val_acc: 0.5283\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 15s 246ms/step - loss: 0.4956 - acc: 0.8519 - val_loss: 1.9270 - val_acc: 0.5367\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 15s 251ms/step - loss: 0.4456 - acc: 0.8568 - val_loss: 1.8819 - val_acc: 0.5467\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 15s 243ms/step - loss: 0.5126 - acc: 0.8275 - val_loss: 2.1185 - val_acc: 0.5100\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 15s 256ms/step - loss: 0.4448 - acc: 0.8615 - val_loss: 2.5403 - val_acc: 0.4817\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 15s 241ms/step - loss: 0.4134 - acc: 0.8601 - val_loss: 2.1827 - val_acc: 0.5117\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 15s 252ms/step - loss: 0.5033 - acc: 0.8349 - val_loss: 2.3245 - val_acc: 0.5133\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 15s 242ms/step - loss: 0.4723 - acc: 0.8408 - val_loss: 1.8731 - val_acc: 0.5533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4fg8WImzBBj"
      },
      "source": [
        "### Feature Extraction Using ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqLddlXVPHYx",
        "execution": {
          "iopub.status.busy": "2021-06-14T12:03:27.464368Z",
          "iopub.execute_input": "2021-06-14T12:03:27.464868Z",
          "iopub.status.idle": "2021-06-14T12:03:28.955718Z",
          "shell.execute_reply.started": "2021-06-14T12:03:27.464824Z",
          "shell.execute_reply": "2021-06-14T12:03:28.954502Z"
        },
        "trusted": true,
        "outputId": "32fe5e3b-ca30-45c0-f26f-dcb8fa4916e7"
      },
      "source": [
        "\n",
        "conv_base = Xception(include_top=False,\n",
        "                  input_shape=(150, 150, 3),\n",
        "                  weights='imagenet')\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 36, 36, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 18, 18, 256)  32768       add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 18, 18, 256)  1024        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 9, 9, 728)    186368      add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 9, 9, 728)    2912        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 5, 5, 1024)   745472      add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 5, 5, 1024)   4096        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vph4ZXAMPHYy",
        "execution": {
          "iopub.status.busy": "2021-06-14T12:03:28.957261Z",
          "iopub.execute_input": "2021-06-14T12:03:28.957667Z",
          "iopub.status.idle": "2021-06-14T12:03:29.392083Z",
          "shell.execute_reply.started": "2021-06-14T12:03:28.957612Z",
          "shell.execute_reply": "2021-06-14T12:03:29.390885Z"
        },
        "trusted": true
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(keras.layers.Flatten())\n",
        "# model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(30, activation='softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ake4yrf6PHYz",
        "execution": {
          "iopub.status.busy": "2021-06-14T12:03:29.393827Z",
          "iopub.execute_input": "2021-06-14T12:03:29.394222Z",
          "iopub.status.idle": "2021-06-14T12:03:29.405235Z",
          "shell.execute_reply.started": "2021-06-14T12:03:29.394179Z",
          "shell.execute_reply": "2021-06-14T12:03:29.403915Z"
        },
        "trusted": true
      },
      "source": [
        "conv_base.trainable = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpcbOE5EPHY0",
        "execution": {
          "iopub.status.busy": "2021-06-14T12:03:29.407001Z",
          "iopub.execute_input": "2021-06-14T12:03:29.407748Z",
          "iopub.status.idle": "2021-06-14T12:03:29.432465Z",
          "shell.execute_reply.started": "2021-06-14T12:03:29.407687Z",
          "shell.execute_reply": "2021-06-14T12:03:29.430736Z"
        },
        "trusted": true,
        "outputId": "bf8e1f47-69ea-4b50-b507-08cdfcc89da3"
      },
      "source": [
        "model.build(input_shape=(None,150, 150, 3))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Functional)        (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 30)                1536030   \n",
            "=================================================================\n",
            "Total params: 22,397,510\n",
            "Trainable params: 1,536,030\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brrcNW6pPHY2",
        "execution": {
          "iopub.status.busy": "2021-06-14T12:03:29.436856Z",
          "iopub.execute_input": "2021-06-14T12:03:29.437145Z",
          "iopub.status.idle": "2021-06-14T12:25:16.347668Z",
          "shell.execute_reply.started": "2021-06-14T12:03:29.437116Z",
          "shell.execute_reply": "2021-06-14T12:25:16.346605Z"
        },
        "trusted": true,
        "outputId": "1bce6b4c-4421-465c-a891-ec48ecfd4b48"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=100,\n",
        "                    validation_data=validation_generator\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 17s 238ms/step - loss: 3.4144 - acc: 0.1106 - val_loss: 2.5361 - val_acc: 0.3350\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 13s 210ms/step - loss: 2.1618 - acc: 0.4203 - val_loss: 2.0656 - val_acc: 0.4683\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 1.6589 - acc: 0.5925 - val_loss: 1.8199 - val_acc: 0.5350\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 1.3833 - acc: 0.6527 - val_loss: 1.6567 - val_acc: 0.5783\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 12s 205ms/step - loss: 1.2587 - acc: 0.6746 - val_loss: 1.5371 - val_acc: 0.6117\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 12s 206ms/step - loss: 1.0187 - acc: 0.7456 - val_loss: 1.4710 - val_acc: 0.6200\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.9428 - acc: 0.7575 - val_loss: 1.4015 - val_acc: 0.6517\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 13s 209ms/step - loss: 0.8835 - acc: 0.7872 - val_loss: 1.3560 - val_acc: 0.6583\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.8209 - acc: 0.8057 - val_loss: 1.3204 - val_acc: 0.6700\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 12s 206ms/step - loss: 0.7974 - acc: 0.7806 - val_loss: 1.2771 - val_acc: 0.6917\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 13s 210ms/step - loss: 0.7684 - acc: 0.8041 - val_loss: 1.2512 - val_acc: 0.6800\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.7036 - acc: 0.8181 - val_loss: 1.2301 - val_acc: 0.6783\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.6882 - acc: 0.8336 - val_loss: 1.1997 - val_acc: 0.6933\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.6716 - acc: 0.8244 - val_loss: 1.1800 - val_acc: 0.6900\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.6667 - acc: 0.8161 - val_loss: 1.1800 - val_acc: 0.6883\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 12s 205ms/step - loss: 0.6160 - acc: 0.8205 - val_loss: 1.1696 - val_acc: 0.6950\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.6019 - acc: 0.8474 - val_loss: 1.1515 - val_acc: 0.7083\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 12s 206ms/step - loss: 0.5228 - acc: 0.8752 - val_loss: 1.1627 - val_acc: 0.7017\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 15s 253ms/step - loss: 0.5521 - acc: 0.8451 - val_loss: 1.1466 - val_acc: 0.7050\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 16s 262ms/step - loss: 0.5522 - acc: 0.8602 - val_loss: 1.1335 - val_acc: 0.7017\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.5611 - acc: 0.8505 - val_loss: 1.1154 - val_acc: 0.7017\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.4921 - acc: 0.8810 - val_loss: 1.0966 - val_acc: 0.7167\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.4547 - acc: 0.8876 - val_loss: 1.0806 - val_acc: 0.7167\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.4883 - acc: 0.8789 - val_loss: 1.1127 - val_acc: 0.7083\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 12s 206ms/step - loss: 0.4221 - acc: 0.8839 - val_loss: 1.1025 - val_acc: 0.6950\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.4571 - acc: 0.8731 - val_loss: 1.0866 - val_acc: 0.7083\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 15s 244ms/step - loss: 0.4268 - acc: 0.8874 - val_loss: 1.0632 - val_acc: 0.7267\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 14s 240ms/step - loss: 0.4253 - acc: 0.8904 - val_loss: 1.0689 - val_acc: 0.7267\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 16s 265ms/step - loss: 0.3903 - acc: 0.9024 - val_loss: 1.0664 - val_acc: 0.7250\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 16s 266ms/step - loss: 0.4332 - acc: 0.8812 - val_loss: 1.0973 - val_acc: 0.7217\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 18s 295ms/step - loss: 0.3916 - acc: 0.8985 - val_loss: 1.0681 - val_acc: 0.7217\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 17s 290ms/step - loss: 0.4343 - acc: 0.8811 - val_loss: 1.0487 - val_acc: 0.7300\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 14s 225ms/step - loss: 0.4212 - acc: 0.8940 - val_loss: 1.0457 - val_acc: 0.7217\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 12s 206ms/step - loss: 0.4007 - acc: 0.9017 - val_loss: 1.0387 - val_acc: 0.7283\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.3858 - acc: 0.9010 - val_loss: 1.0132 - val_acc: 0.7383\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 15s 249ms/step - loss: 0.3498 - acc: 0.9048 - val_loss: 1.0149 - val_acc: 0.7383\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.3583 - acc: 0.9097 - val_loss: 1.0363 - val_acc: 0.7317\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.3916 - acc: 0.8986 - val_loss: 1.0359 - val_acc: 0.7267\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.3594 - acc: 0.8980 - val_loss: 1.0340 - val_acc: 0.7267\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.3880 - acc: 0.8844 - val_loss: 1.0341 - val_acc: 0.7267\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.3145 - acc: 0.9187 - val_loss: 1.0223 - val_acc: 0.7467\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.3271 - acc: 0.9153 - val_loss: 1.0028 - val_acc: 0.7350\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.3218 - acc: 0.9074 - val_loss: 1.0038 - val_acc: 0.7417\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.3488 - acc: 0.8978 - val_loss: 1.0168 - val_acc: 0.7400\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.3278 - acc: 0.9059 - val_loss: 1.0267 - val_acc: 0.7417\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.3166 - acc: 0.9190 - val_loss: 1.0262 - val_acc: 0.7267\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 12s 206ms/step - loss: 0.3116 - acc: 0.9306 - val_loss: 1.0138 - val_acc: 0.7367\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.3107 - acc: 0.9286 - val_loss: 1.0005 - val_acc: 0.7417\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.2900 - acc: 0.9383 - val_loss: 1.0006 - val_acc: 0.7350\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 12s 206ms/step - loss: 0.3243 - acc: 0.9220 - val_loss: 0.9989 - val_acc: 0.7283\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 12s 205ms/step - loss: 0.3002 - acc: 0.9092 - val_loss: 0.9972 - val_acc: 0.7350\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.2630 - acc: 0.9386 - val_loss: 0.9859 - val_acc: 0.7383\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.2932 - acc: 0.9165 - val_loss: 1.0132 - val_acc: 0.7350\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.2723 - acc: 0.9316 - val_loss: 0.9826 - val_acc: 0.7467\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.2750 - acc: 0.9374 - val_loss: 0.9683 - val_acc: 0.7517\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 13s 210ms/step - loss: 0.2840 - acc: 0.9203 - val_loss: 0.9994 - val_acc: 0.7400\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2445 - acc: 0.9376 - val_loss: 0.9662 - val_acc: 0.7517\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 12s 205ms/step - loss: 0.2627 - acc: 0.9326 - val_loss: 0.9563 - val_acc: 0.7550\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.2548 - acc: 0.9397 - val_loss: 0.9699 - val_acc: 0.7433\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 15s 240ms/step - loss: 0.2830 - acc: 0.9180 - val_loss: 0.9778 - val_acc: 0.7433\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 13s 211ms/step - loss: 0.2343 - acc: 0.9364 - val_loss: 0.9908 - val_acc: 0.7500\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2527 - acc: 0.9464 - val_loss: 0.9812 - val_acc: 0.7450\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.2860 - acc: 0.9200 - val_loss: 0.9936 - val_acc: 0.7400\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.2447 - acc: 0.9271 - val_loss: 0.9745 - val_acc: 0.7433\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.2440 - acc: 0.9431 - val_loss: 0.9684 - val_acc: 0.7400\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.2258 - acc: 0.9405 - val_loss: 0.9523 - val_acc: 0.7533\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.2443 - acc: 0.9302 - val_loss: 0.9752 - val_acc: 0.7450\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.2258 - acc: 0.9493 - val_loss: 0.9886 - val_acc: 0.7417\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.2496 - acc: 0.9316 - val_loss: 0.9599 - val_acc: 0.7467\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 14s 227ms/step - loss: 0.2527 - acc: 0.9269 - val_loss: 0.9508 - val_acc: 0.7467\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.2253 - acc: 0.9450 - val_loss: 0.9708 - val_acc: 0.7450\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.2107 - acc: 0.9410 - val_loss: 0.9652 - val_acc: 0.7417\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.2313 - acc: 0.9434 - val_loss: 0.9700 - val_acc: 0.7367\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 13s 209ms/step - loss: 0.2061 - acc: 0.9500 - val_loss: 0.9806 - val_acc: 0.7450\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.2093 - acc: 0.9515 - val_loss: 0.9652 - val_acc: 0.7483\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 13s 211ms/step - loss: 0.2400 - acc: 0.9250 - val_loss: 0.9628 - val_acc: 0.7450\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.2064 - acc: 0.9402 - val_loss: 0.9630 - val_acc: 0.7367\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 15s 244ms/step - loss: 0.2070 - acc: 0.9517 - val_loss: 0.9573 - val_acc: 0.7433\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 12s 206ms/step - loss: 0.2009 - acc: 0.9394 - val_loss: 0.9605 - val_acc: 0.7433\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.1886 - acc: 0.9556 - val_loss: 0.9768 - val_acc: 0.7367\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.2338 - acc: 0.9372 - val_loss: 0.9576 - val_acc: 0.7450\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.1919 - acc: 0.9513 - val_loss: 0.9752 - val_acc: 0.7450\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2256 - acc: 0.9302 - val_loss: 0.9730 - val_acc: 0.7417\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.2188 - acc: 0.9408 - val_loss: 0.9850 - val_acc: 0.7317\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2044 - acc: 0.9452 - val_loss: 0.9727 - val_acc: 0.7333\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 12s 206ms/step - loss: 0.1917 - acc: 0.9501 - val_loss: 0.9655 - val_acc: 0.7333\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.1664 - acc: 0.9592 - val_loss: 0.9609 - val_acc: 0.7350\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1934 - acc: 0.9476 - val_loss: 0.9675 - val_acc: 0.7367\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.2101 - acc: 0.9458 - val_loss: 0.9698 - val_acc: 0.7250\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.2393 - acc: 0.9286 - val_loss: 0.9322 - val_acc: 0.7433\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.1714 - acc: 0.9529 - val_loss: 0.9520 - val_acc: 0.7467\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.1948 - acc: 0.9443 - val_loss: 0.9332 - val_acc: 0.7583\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.1712 - acc: 0.9526 - val_loss: 0.9504 - val_acc: 0.7450\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.1931 - acc: 0.9492 - val_loss: 0.9419 - val_acc: 0.7500\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.1790 - acc: 0.9609 - val_loss: 0.9444 - val_acc: 0.7433\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.1816 - acc: 0.9559 - val_loss: 0.9591 - val_acc: 0.7500\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.1948 - acc: 0.9436 - val_loss: 0.9651 - val_acc: 0.7400\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.1861 - acc: 0.9490 - val_loss: 0.9658 - val_acc: 0.7533\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.1813 - acc: 0.9533 - val_loss: 0.9867 - val_acc: 0.7367\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 13s 211ms/step - loss: 0.1875 - acc: 0.9489 - val_loss: 0.9627 - val_acc: 0.7383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsvLcJ_kCXn_",
        "execution": {
          "iopub.status.busy": "2021-06-14T12:25:16.351861Z",
          "iopub.execute_input": "2021-06-14T12:25:16.352256Z",
          "iopub.status.idle": "2021-06-14T12:25:16.359855Z",
          "shell.execute_reply.started": "2021-06-14T12:25:16.352226Z",
          "shell.execute_reply": "2021-06-14T12:25:16.358789Z"
        },
        "trusted": true
      },
      "source": [
        "\n",
        "# conv_base = Xception(include_top=False,\n",
        "#                   input_shape=(150, 150, 3),\n",
        "#                   weights='imagenet')\n",
        "\n",
        "# conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZd_yLXgzrua"
      },
      "source": [
        "### Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rheQzlh6CafG",
        "execution": {
          "iopub.status.busy": "2021-06-14T12:25:16.361468Z",
          "iopub.execute_input": "2021-06-14T12:25:16.361955Z",
          "iopub.status.idle": "2021-06-14T12:25:16.396131Z",
          "shell.execute_reply.started": "2021-06-14T12:25:16.361907Z",
          "shell.execute_reply": "2021-06-14T12:25:16.394633Z"
        },
        "trusted": true,
        "outputId": "df1b6021-c9d7-443b-d9d1-689a2ec7341f"
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block12_sepconv1':\n",
        "    set_trainable = True\n",
        "\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Functional)        (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 30)                1536030   \n",
            "=================================================================\n",
            "Total params: 22,397,510\n",
            "Trainable params: 9,938,390\n",
            "Non-trainable params: 12,459,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ndlJQ35DaMt",
        "execution": {
          "iopub.status.busy": "2021-06-14T12:25:16.398249Z",
          "iopub.execute_input": "2021-06-14T12:25:16.398731Z",
          "iopub.status.idle": "2021-06-14T12:47:43.678215Z",
          "shell.execute_reply.started": "2021-06-14T12:25:16.398686Z",
          "shell.execute_reply": "2021-06-14T12:47:43.677172Z"
        },
        "trusted": true,
        "outputId": "ce390341-8438-4629-c6c8-861c9ba6e404"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=100,\n",
        "                    validation_data=validation_generator\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60/60 [==============================] - 19s 252ms/step - loss: 1.3545 - acc: 0.7064 - val_loss: 1.0718 - val_acc: 0.7167\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.8309 - acc: 0.8333 - val_loss: 1.0572 - val_acc: 0.7367\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - 13s 225ms/step - loss: 0.6589 - acc: 0.8542 - val_loss: 0.9857 - val_acc: 0.7350\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.4729 - acc: 0.9150 - val_loss: 0.9162 - val_acc: 0.7550\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.4748 - acc: 0.8772 - val_loss: 0.8756 - val_acc: 0.7583\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.3297 - acc: 0.9290 - val_loss: 0.8783 - val_acc: 0.7550\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.3248 - acc: 0.9151 - val_loss: 0.8320 - val_acc: 0.7717\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.3302 - acc: 0.9174 - val_loss: 0.8308 - val_acc: 0.7783\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - 14s 230ms/step - loss: 0.2598 - acc: 0.9383 - val_loss: 0.7726 - val_acc: 0.7900\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.2223 - acc: 0.9397 - val_loss: 0.7546 - val_acc: 0.7850\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - 14s 230ms/step - loss: 0.2126 - acc: 0.9473 - val_loss: 0.7285 - val_acc: 0.8067\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.2209 - acc: 0.9420 - val_loss: 0.7268 - val_acc: 0.7917\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.1822 - acc: 0.9591 - val_loss: 0.7023 - val_acc: 0.7983\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.1640 - acc: 0.9527 - val_loss: 0.6853 - val_acc: 0.8083\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - 13s 210ms/step - loss: 0.2004 - acc: 0.9527 - val_loss: 0.6688 - val_acc: 0.8033\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - 14s 227ms/step - loss: 0.1624 - acc: 0.9603 - val_loss: 0.6886 - val_acc: 0.7983\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - 13s 211ms/step - loss: 0.1612 - acc: 0.9588 - val_loss: 0.6720 - val_acc: 0.8067\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.1609 - acc: 0.9652 - val_loss: 0.6574 - val_acc: 0.8100\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1248 - acc: 0.9723 - val_loss: 0.6627 - val_acc: 0.8133\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - 13s 210ms/step - loss: 0.1172 - acc: 0.9750 - val_loss: 0.6579 - val_acc: 0.8167\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1053 - acc: 0.9742 - val_loss: 0.6506 - val_acc: 0.8133\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.1242 - acc: 0.9717 - val_loss: 0.6563 - val_acc: 0.8200\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.1076 - acc: 0.9716 - val_loss: 0.6596 - val_acc: 0.8167\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1244 - acc: 0.9607 - val_loss: 0.6353 - val_acc: 0.8200\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - 13s 211ms/step - loss: 0.1218 - acc: 0.9644 - val_loss: 0.6410 - val_acc: 0.8267\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0973 - acc: 0.9786 - val_loss: 0.6234 - val_acc: 0.8217\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.0772 - acc: 0.9821 - val_loss: 0.6057 - val_acc: 0.8350\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.0995 - acc: 0.9678 - val_loss: 0.6200 - val_acc: 0.8400\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0918 - acc: 0.9768 - val_loss: 0.6303 - val_acc: 0.8317\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - 14s 232ms/step - loss: 0.0835 - acc: 0.9805 - val_loss: 0.6189 - val_acc: 0.8267\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - 17s 277ms/step - loss: 0.1008 - acc: 0.9701 - val_loss: 0.6193 - val_acc: 0.8233\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - 14s 229ms/step - loss: 0.0988 - acc: 0.9759 - val_loss: 0.6157 - val_acc: 0.8367\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0904 - acc: 0.9773 - val_loss: 0.6169 - val_acc: 0.8267\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.0682 - acc: 0.9833 - val_loss: 0.6266 - val_acc: 0.8267\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.0775 - acc: 0.9803 - val_loss: 0.6088 - val_acc: 0.8283\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - 14s 229ms/step - loss: 0.0701 - acc: 0.9825 - val_loss: 0.5835 - val_acc: 0.8383\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.0936 - acc: 0.9773 - val_loss: 0.6019 - val_acc: 0.8300\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.0645 - acc: 0.9827 - val_loss: 0.5923 - val_acc: 0.8367\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.0467 - acc: 0.9893 - val_loss: 0.5864 - val_acc: 0.8400\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.0564 - acc: 0.9886 - val_loss: 0.5883 - val_acc: 0.8517\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - 14s 228ms/step - loss: 0.0605 - acc: 0.9903 - val_loss: 0.6088 - val_acc: 0.8367\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.0601 - acc: 0.9853 - val_loss: 0.6057 - val_acc: 0.8367\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0613 - acc: 0.9868 - val_loss: 0.6023 - val_acc: 0.8350\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.0754 - acc: 0.9787 - val_loss: 0.5934 - val_acc: 0.8417\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0468 - acc: 0.9892 - val_loss: 0.5875 - val_acc: 0.8433\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - 14s 228ms/step - loss: 0.0440 - acc: 0.9908 - val_loss: 0.5791 - val_acc: 0.8450\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.0465 - acc: 0.9927 - val_loss: 0.5887 - val_acc: 0.8367\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - 13s 224ms/step - loss: 0.0389 - acc: 0.9949 - val_loss: 0.5682 - val_acc: 0.8433\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.0451 - acc: 0.9861 - val_loss: 0.5813 - val_acc: 0.8433\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.0420 - acc: 0.9918 - val_loss: 0.5817 - val_acc: 0.8517\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - 14s 227ms/step - loss: 0.0568 - acc: 0.9826 - val_loss: 0.6296 - val_acc: 0.8467\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.0676 - acc: 0.9847 - val_loss: 0.5924 - val_acc: 0.8400\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - 13s 223ms/step - loss: 0.0465 - acc: 0.9900 - val_loss: 0.5966 - val_acc: 0.8433\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.0589 - acc: 0.9809 - val_loss: 0.6004 - val_acc: 0.8483\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.0362 - acc: 0.9918 - val_loss: 0.5951 - val_acc: 0.8467\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - 14s 236ms/step - loss: 0.0493 - acc: 0.9933 - val_loss: 0.5839 - val_acc: 0.8517\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - 13s 224ms/step - loss: 0.0403 - acc: 0.9865 - val_loss: 0.5945 - val_acc: 0.8483\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0476 - acc: 0.9913 - val_loss: 0.5928 - val_acc: 0.8467\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.0398 - acc: 0.9879 - val_loss: 0.5787 - val_acc: 0.8500\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - 15s 247ms/step - loss: 0.0329 - acc: 0.9915 - val_loss: 0.5886 - val_acc: 0.8433\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - 17s 287ms/step - loss: 0.0446 - acc: 0.9855 - val_loss: 0.5992 - val_acc: 0.8433\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - 17s 282ms/step - loss: 0.0460 - acc: 0.9890 - val_loss: 0.6046 - val_acc: 0.8467\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - 17s 283ms/step - loss: 0.0386 - acc: 0.9910 - val_loss: 0.5788 - val_acc: 0.8517\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - 16s 275ms/step - loss: 0.0369 - acc: 0.9932 - val_loss: 0.5918 - val_acc: 0.8433\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.0347 - acc: 0.9938 - val_loss: 0.6120 - val_acc: 0.8517\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.0386 - acc: 0.9862 - val_loss: 0.6295 - val_acc: 0.8467\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0356 - acc: 0.9910 - val_loss: 0.6144 - val_acc: 0.8467\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.0405 - acc: 0.9864 - val_loss: 0.6127 - val_acc: 0.8550\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - 14s 226ms/step - loss: 0.0316 - acc: 0.9900 - val_loss: 0.6062 - val_acc: 0.8550\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.0207 - acc: 0.9989 - val_loss: 0.6169 - val_acc: 0.8550\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.0312 - acc: 0.9914 - val_loss: 0.6297 - val_acc: 0.8433\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0270 - acc: 0.9926 - val_loss: 0.6155 - val_acc: 0.8567\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.0323 - acc: 0.9921 - val_loss: 0.6203 - val_acc: 0.8583\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - 16s 274ms/step - loss: 0.0205 - acc: 0.9937 - val_loss: 0.6038 - val_acc: 0.8517\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - 15s 244ms/step - loss: 0.0207 - acc: 0.9979 - val_loss: 0.5883 - val_acc: 0.8483\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0243 - acc: 0.9962 - val_loss: 0.5778 - val_acc: 0.8617\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0205 - acc: 0.9954 - val_loss: 0.5773 - val_acc: 0.8617\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0179 - acc: 0.9988 - val_loss: 0.5950 - val_acc: 0.8550\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0228 - acc: 0.9929 - val_loss: 0.6014 - val_acc: 0.8650\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.0291 - acc: 0.9917 - val_loss: 0.6157 - val_acc: 0.8583\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - 14s 229ms/step - loss: 0.0294 - acc: 0.9914 - val_loss: 0.6140 - val_acc: 0.8517\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.0614 - acc: 0.9840 - val_loss: 0.5721 - val_acc: 0.8617\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.0231 - acc: 0.9941 - val_loss: 0.5847 - val_acc: 0.8633\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - 13s 225ms/step - loss: 0.0283 - acc: 0.9921 - val_loss: 0.6138 - val_acc: 0.8633\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.0330 - acc: 0.9923 - val_loss: 0.6251 - val_acc: 0.8533\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - 13s 223ms/step - loss: 0.0232 - acc: 0.9936 - val_loss: 0.5944 - val_acc: 0.8600\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - 13s 223ms/step - loss: 0.0211 - acc: 0.9924 - val_loss: 0.6276 - val_acc: 0.8517\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.0299 - acc: 0.9908 - val_loss: 0.6319 - val_acc: 0.8500\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - 14s 240ms/step - loss: 0.0188 - acc: 0.9966 - val_loss: 0.6460 - val_acc: 0.8533\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.0195 - acc: 0.9955 - val_loss: 0.6288 - val_acc: 0.8517\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - 13s 223ms/step - loss: 0.0303 - acc: 0.9910 - val_loss: 0.6273 - val_acc: 0.8500\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.0241 - acc: 0.9945 - val_loss: 0.6425 - val_acc: 0.8567\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.0175 - acc: 0.9967 - val_loss: 0.6351 - val_acc: 0.8583\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.0198 - acc: 0.9918 - val_loss: 0.6321 - val_acc: 0.8583\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.0192 - acc: 0.9936 - val_loss: 0.5975 - val_acc: 0.8683\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - 13s 224ms/step - loss: 0.0166 - acc: 0.9963 - val_loss: 0.5879 - val_acc: 0.8583\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.0214 - acc: 0.9920 - val_loss: 0.6006 - val_acc: 0.8583\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - 14s 239ms/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.6298 - val_acc: 0.8600\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - 15s 251ms/step - loss: 0.0133 - acc: 0.9965 - val_loss: 0.6394 - val_acc: 0.8500\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.0115 - acc: 0.9973 - val_loss: 0.6203 - val_acc: 0.8617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-RfMM6zDyKH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}