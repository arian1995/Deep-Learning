{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep-Learning-HW03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPXTSeThdEWC"
      },
      "source": [
        "# Deep Learning 3rd Assignment - Part a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UPR9eNJdLZT"
      },
      "source": [
        "In this section you should implement Adam algorithm with numpy on the following objective function:\n",
        "\\begin{equation}\n",
        "x^2 + y^2\n",
        "\\end{equation}\n",
        "Try and analyze the performance of this algorithm with different values for beta1 and beta2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG5EKiOsdXSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5cd909-ccb2-4f3e-cc5f-5f5fc64350ac"
      },
      "source": [
        "### Write Your Code Here ###\n",
        "import numpy as np\n",
        "def objective_function(x, y):\n",
        "  return x**2 + y**2\n",
        "\n",
        "def compute_gradient(x, y):\n",
        "  return np.array([2.0 * x, 2.0 * y])\n",
        "\n",
        "def adam(learning_rate, number_of_iterations, beta1, beta2, var_limit):\n",
        "  var = var_limit[:, 0] + np.random.rand(len(var_limit)) * (var_limit[:, 1] - var_limit[:, 0])\n",
        "  objective_value = objective_function(var[0], var[1])\n",
        "  first_moment = [0 for el in range(var_limit.shape[0])]\n",
        "  second_moment = [0 for el in range(var_limit.shape[0])]\n",
        "\n",
        "  for t in range(1, number_of_iterations):\n",
        "    grad = compute_gradient(var[0], var[1])\n",
        "    for i in range(var.shape[0]):\n",
        "      first_moment[i] = beta1 * first_moment[i] + (1 - beta1) * grad[i]\n",
        "      second_moment[i] = beta2 * second_moment[i] + (1 - beta2) * grad[i] * grad[i]\n",
        "\n",
        "      first_unbias = first_moment[i] / (1.0 - beta1 ** t)\n",
        "      second_unbias = second_moment[i] / (1.0 - beta2 ** t)\n",
        "\n",
        "      var[i] -= learning_rate * first_unbias / (np.sqrt(second_unbias) + 1e-7)\n",
        "    objective_value = objective_function(var[0], var[1])\n",
        "      \n",
        "      \n",
        "\n",
        "  return var, objective_value\n",
        "\n",
        "learning_rate = 1e-1\n",
        "number_of_iterations = 100\n",
        "beta1 = 0.1\n",
        "beta2 = 0.999\n",
        "var_limit = np.array([[-1, 1], [-1, 1]])\n",
        "adam(learning_rate, number_of_iterations, beta1, beta2, var_limit)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1.09655876e-22,  3.86495570e-43]), 1.2024411173779359e-44)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-crMo4Hde-Vg"
      },
      "source": [
        "Please write your observations and conclusion of running the algorithm with different values for beta1 and beta2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZEmFRvkfQw4"
      },
      "source": [
        "<font color='red'>if beta2 is less than and almost equal to 1 the result is better and if beta2 is almost equal to zero the result gets worse and about beta1 usually if beta1 is greater than but almost equal to 0 the result is better and as betal goes up the result gets worse.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_aJl-g0lN8M"
      },
      "source": [
        "# Deep Learning 3rd Assignment - Part b\n",
        "\n",
        "---\n",
        "\n",
        "In this assignment we will be focusing on optimizing neural networks. As you may already know Keras API has a lot of built-in functions for optimization that you can use. However you may want to impelement your own custom optimization function or design one for your specific problem.\n",
        "\n",
        "The purpose of this notebook is to teach you to implement your own optimization function by using Keras API.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egTG4I4b1XvR",
        "cellView": "form"
      },
      "source": [
        "#@title Import necessary modules\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.optimizers import Optimizer\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUFk7FaA1L-9"
      },
      "source": [
        "To keep things rather simple and draw our full attention towards implementing custom optimization functions, we use a simple classification problem. The first step is to prepare our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2n8keC22og1"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeFbGgzx2uXv"
      },
      "source": [
        "Run the code below to load and plot the handwritten digit recognition dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "C1Q_ukmlktUN",
        "outputId": "19d10e6d-a73e-4851-a0d3-74f49df2398f"
      },
      "source": [
        "# Load the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TE7jDSnOH-i"
      },
      "source": [
        "Since we have not yet studied Convolutional Neural Networks (AKA CNN), we would like to solve this problem by using Multi-Layer Perceptrons. \n",
        "\n",
        "Note that our data is two-dimensional and since we are not using CNNs, we should reshape our data to make it compatible for MLPs. In the following code cell convert the input shape to a vector of pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pypr9kl4Qfg8"
      },
      "source": [
        "# Reshape the test and training datasets \n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "X_test = X_test.reshape(X_test.shape[0],-1)\n",
        "\n",
        "# Normalizing data\n",
        "\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARmIcHrRRRfi"
      },
      "source": [
        "Now since our problem is a multi-class classification problem we should label our data from 0 to 9 (there are 10 handwritten digits). We can simply do this using keras's built-in to_categorical() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTHiVaQER1cc",
        "outputId": "a4d010f4-4c6c-43db-9e84-ca8d39308791"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mycw9cVoTlRt"
      },
      "source": [
        "## Defining Our Custom Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LicS7nyYTrz_"
      },
      "source": [
        "This is the main part of this assignment because you are going to implement your custom optimizer. \n",
        "\n",
        "Below you should implement the SGD algorithm that you have learned in class. The class inherits from the Optimizer class in Keras. So all you need to do is to overwrite the functions specified below to have your own custom optimizer. \n",
        "\n",
        "In the constructor section you should define your hyperparameters and in resource_apply_dence function you write your main algorithm for optimizing.\n",
        "\n",
        "You can visit [here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer) to get further information on how to implement your own optimizer in tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWBwHr7G_Mn6"
      },
      "source": [
        "class CustomSGD(Optimizer):\n",
        "    def __init__(self, learning_rate=0.01, name=\"CustomSGD\", **kwargs):\n",
        "        \"\"\"you can set and store your hyper-parameters here\"\"\"\n",
        "        super().__init__(name, **kwargs)\n",
        "        \"\"\"Define learning rate hyper param here\"\"\"\n",
        "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
        "        # self._is_first = True\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        \"\"\" This is where you implement SGD algorithm with decayed learning rate \"\"\"\n",
        "        var_dtype = var.dtype.base_dtype\n",
        "        lr_t = self._decayed_lr(var_dtype) # handle learning rate decay\n",
        "\n",
        "        new_var = var - grad * lr_t\n",
        "        var.assign(new_var)\n",
        "    def _resource_apply_sparse(self, grad, var):\n",
        "        \"\"\" No need to do anything here \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
        "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJPHYkn7S0Qi"
      },
      "source": [
        "## Creating Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOXiK6WwS7Te"
      },
      "source": [
        "In this section we will create our model. You only need dense layers and don't forget to use your custom SGD. Also try changing the learning rate of the optimizer and analyze the effect of the learning rate on your model's performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut2qNgjeTSru"
      },
      "source": [
        "def mlp_model():\n",
        "    # create model here\n",
        "    model = tf.keras.Sequential()\n",
        "    # model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "    # model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "    \n",
        "    # Compile model here \n",
        "    optimizer = CustomSGD(learning_rate=0.5)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFI65r3YZD3b"
      },
      "source": [
        "Now run the following code cell to train and evaluate our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgzRoV3PalVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dcce3e1-c307-426f-dc7e-fcf886eb96b8"
      },
      "source": [
        "model = mlp_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Model Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 2s - loss: 0.3520 - accuracy: 0.8937 - val_loss: 0.1823 - val_accuracy: 0.9472\n",
            "Epoch 2/10\n",
            "300/300 - 1s - loss: 0.1551 - accuracy: 0.9553 - val_loss: 0.1293 - val_accuracy: 0.9613\n",
            "Epoch 3/10\n",
            "300/300 - 1s - loss: 0.1141 - accuracy: 0.9670 - val_loss: 0.1013 - val_accuracy: 0.9703\n",
            "Epoch 4/10\n",
            "300/300 - 1s - loss: 0.0907 - accuracy: 0.9738 - val_loss: 0.0961 - val_accuracy: 0.9705\n",
            "Epoch 5/10\n",
            "300/300 - 1s - loss: 0.0755 - accuracy: 0.9780 - val_loss: 0.0860 - val_accuracy: 0.9731\n",
            "Epoch 6/10\n",
            "300/300 - 1s - loss: 0.0632 - accuracy: 0.9822 - val_loss: 0.0863 - val_accuracy: 0.9729\n",
            "Epoch 7/10\n",
            "300/300 - 1s - loss: 0.0549 - accuracy: 0.9842 - val_loss: 0.0831 - val_accuracy: 0.9738\n",
            "Epoch 8/10\n",
            "300/300 - 1s - loss: 0.0485 - accuracy: 0.9860 - val_loss: 0.0752 - val_accuracy: 0.9748\n",
            "Epoch 9/10\n",
            "300/300 - 1s - loss: 0.0420 - accuracy: 0.9880 - val_loss: 0.0683 - val_accuracy: 0.9783\n",
            "Epoch 10/10\n",
            "300/300 - 1s - loss: 0.0369 - accuracy: 0.9898 - val_loss: 0.0707 - val_accuracy: 0.9769\n",
            "Model Error: 2.31%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0H2zUdOxAqm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}